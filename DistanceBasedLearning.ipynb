{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistanceBasedLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Ee_PILA4IJWN",
        "peA9CqHzIgyR",
        "ZBGpCUBudPfM",
        "ftfT02r3X1Sw",
        "qAm6NfqFamzz",
        "eQCEm94jHrNg",
        "K6DF2HCgzNoO",
        "YkH--BQHNsON",
        "fV7cYZNuNuoS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swampxx/DistanceBasedLearning/blob/master/DistanceBasedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ee_PILA4IJWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "lFcQMRGKIR7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -r CMANN\n",
        "#!git clone https://github.com/Orkun-tanik/CMANN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "peA9CqHzIgyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Omniglot"
      ]
    },
    {
      "metadata": {
        "id": "48OyelLWJQYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The Omniglot* dataset is a collection of 1623 hand drawn characters from 50 alphabets. For every character there are just 20 examples, each drawn by a different person at resolution 105x105."
      ]
    },
    {
      "metadata": {
        "id": "rJjxbj1QJT4_",
        "colab_type": "code",
        "outputId": "f5a5323d-9619-4e88-d6ec-ff296fff4f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#!unzip CMANN/images_evaluation.zip\n",
        "#!unzip CMANN/images_background.zip\n",
        "\n",
        "\"\"\"  Do not execute again!!  \"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Do not execute again!!  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "K1GOfegpNEtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyQ4fqrQdBVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_origin(image):\n",
        "    \"\"\"\n",
        "       Image: Black pixels labeled as True\n",
        "        \n",
        "       It moves the image towards the origin,\n",
        "                returns new_image and black pixels coordinates array: (new_image,blacks)  \n",
        "                \n",
        "    \"\"\"\n",
        "\n",
        "    x,y = image.shape\n",
        "    xshift = x\n",
        "    yshift = y\n",
        "\n",
        "    blacks = []\n",
        "\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j))\n",
        "                if i<xshift:\n",
        "                    xshift = i\n",
        "                if j<yshift:\n",
        "                    yshift = j\n",
        "\n",
        "    new_image = np.zeros(shape=(x,y))\n",
        "\n",
        "    for i in range(len(blacks)):\n",
        "        (a,b) = blacks[i]\n",
        "        blacks[i] = (a-xshift, b-yshift)\n",
        "        new_image[a-xshift][b-yshift] = 1\n",
        "    \n",
        "    blacks = np.array(blacks)\n",
        "\n",
        "    return (new_image, blacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Mli7B2nJljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = \"\"\n",
        "train_path = os.path.join(data_path,'images_background')\n",
        "validation_path = os.path.join(data_path,'images_evaluation')\n",
        "\n",
        "\n",
        "\n",
        "def load_images_from_directory(path):\n",
        "    X=[]\n",
        "\n",
        "    ## We load every alphabet seperately and append that to one tensor\n",
        "    for alphabet in os.listdir(path):\n",
        "        #print(\"loading alphabet: \" + alphabet)\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        \n",
        "        ## Each character in alphabet is in a separate folder\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            #print(\" + letter: \" + letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "        \n",
        "            \n",
        "            if not os.path.isdir(letter_path):\n",
        "                continue\n",
        "\n",
        "            ## Read every image in this directory\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = mpimg.imread(image_path)\n",
        "                #print(image)\n",
        "                \n",
        "                \n",
        "                #TODO: recreate images with black pixels coordinate values\n",
        "                \n",
        "                \n",
        "                ## Image preprocessing!\n",
        "                #image = image/255\n",
        "                #image = 1-image\n",
        "                \n",
        "                image = np.logical_not(image)\n",
        "                #print(\"prepocessing image...\")\n",
        "                \n",
        "                new_image, _ = to_origin(image)\n",
        "                \n",
        "                \n",
        "                #print(\"done.\")\n",
        "                #print(image)           \n",
        "                \n",
        "                category_images.append(new_image)\n",
        "            \n",
        "            try:\n",
        "                X.append(np.array(category_images))\n",
        "            #edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "    \n",
        "    X = np.array(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gwvm2R90PCFK",
        "colab_type": "code",
        "outputId": "304c614a-0b1b-4ecb-ac46-f8c9887535bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Loading training set\")\n",
        "#Xtrain = load_images_from_directory(train_path)\n",
        "#print(Xtrain.shape)\n",
        "\n",
        "print(\"Now loading evaluation set\")\n",
        "#Xval = load_images_from_directory(validation_path)\n",
        "#print(Xval.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training set\n",
            "Now loading evaluation set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jHsxmnlPNgm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.save('Xtrain.npy', Xtrain)\n",
        "#np.save('Xval.npy', Xval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEaVm3uTuTpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Xtrain = np.load(\"Xtrain.npy\")\n",
        "#Xval = np.load(\"Xval.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Lzrn79ENmN_",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "f304a4d4-d115-42a5-c1c2-c0dcc40ab9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"#@title Example Image to be displayed { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 270 #@param {type:\"integer\"}\n",
        "drawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "\n",
        "if (image_set == 'Xval'):\n",
        "    imgplot = plt.imshow(Xval[character,drawing])\n",
        "else:\n",
        "    imgplot = plt.imshow(Xtrain[character,drawing])\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#@title Example Image to be displayed { run: \"auto\" }\\nimport matplotlib.pyplot as plt\\n\\ncharacter = 270 #@param {type:\"integer\"}\\ndrawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\\nimage_set = \\'Xtrain\\' #@param [\"Xval\", \"Xtrain\"]\\n\\nif (image_set == \\'Xval\\'):\\n    imgplot = plt.imshow(Xval[character,drawing])\\nelse:\\n    imgplot = plt.imshow(Xtrain[character,drawing])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "P2YL-GHSV2zL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Latin Images"
      ]
    },
    {
      "metadata": {
        "id": "Ct5DyzmNWjc3",
        "colab_type": "code",
        "outputId": "fc2bf946-921d-41d3-88af-7ee794354358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "latin_path = \"Latin\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "latin = load_images_from_directory(latin_path)\n",
        "print(latin.shape)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(26, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8lU37kuPT_j",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "1312e071-4d4c-4f42-eeaf-db76b3d5304a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin[character,drawing])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9424a00f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "eiOL3XzPQE6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def black_pixels(image):\n",
        "    \"\"\"\n",
        "       returns black pixel coordinates of image, array-like\n",
        "    \"\"\"\n",
        "    \n",
        "    x,y = image.shape\n",
        "    blacks = []\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j)) \n",
        "\n",
        "\n",
        "\n",
        "    return np.array(blacks)\n",
        "\n",
        "# Extract random samples from each character of given alphabet\n",
        "\n",
        "def _get_sample(alphabet):\n",
        "    \n",
        "    \"\"\"\n",
        "        alphabet numpy array [size, drawing, 105, 105]\n",
        "    \n",
        "        returns samples and altered alphabet\n",
        "    \"\"\"\n",
        "    character_count, drawing_count, _, _ = alphabet.shape\n",
        "    samples = []\n",
        "    new_alphabet = []    \n",
        "    for i in range(character_count):\n",
        "        rand = np.random.randint(0,drawing_count)\n",
        "        samples.append(alphabet[i,rand])\n",
        "        new_alphabet.append(np.delete(alphabet[i], rand, 0))  \n",
        "    \n",
        "    \n",
        "    samples = np.array(samples)\n",
        "    new_alphabet = np.array(new_alphabet)\n",
        "    \n",
        "    return samples, new_alphabet\n",
        "\n",
        "def get_sample(alphabet, size):\n",
        "    character_count, drawing_count, _, _ = alphabet.shape\n",
        "    samples = []\n",
        "    new_alphabet = []    \n",
        "    for i in range(character_count):\n",
        "        alp = alphabet[i]\n",
        "        rand = np.random.permutation(drawing_count)[:size]\n",
        "        samples.append(alp[rand[:]])\n",
        "        new_alphabet.append(np.delete(alp,rand,0))\n",
        "        \n",
        "    samples = np.array(samples)\n",
        "    new_alphabet = np.array(new_alphabet)\n",
        "    \n",
        "    return samples, new_alphabet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmQanN0cR1L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "latin_samples, new_latin = _get_sample(latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WVbYpnfwS5PP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "latin_samples2, new_latin2 = get_sample(latin,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEtqxXxMU9LV",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "862eddb7-614a-4da1-9a54-7fba56dd46b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 3 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 1 #@param {type:\"slider\", min:0, max:1, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin_samples2[character, drawing])"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9234c2588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IIxwKGRMWK3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***These sample latin images will be used for testing distance functions. ***"
      ]
    },
    {
      "metadata": {
        "id": "ZBGpCUBudPfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Greek Images\n"
      ]
    },
    {
      "metadata": {
        "id": "zbwc4pR9dasc",
        "colab_type": "code",
        "outputId": "ee256f6e-566a-4b78-93ad-2775479539b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "greek_path = \"Greek\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "greek = load_images_from_directory(greek_path)\n",
        "print(greek.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(24, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FBQWGFEdyf5",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "2fd9a8e4-7f87-4503-8469-24416bfead7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek[character,drawing])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa942170d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_wl7kyGMd6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "greek_samples, new_greek = get_sample(greek)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVN57oPWd_KJ",
        "colab_type": "code",
        "outputId": "9e8ccb7d-22d2-49e3-924e-66e3d8d2794a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 16 #@param {type:\"slider\", min:0, max:23, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek_samples[character])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9421597f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3u3QOMrMWgkJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*In this section,  there are experiments of distance functions for one-shot learning . Follow the headers for distance functions properties.*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ftfT02r3X1Sw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elementary Distance Functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "* Minkowski Family\n",
        "> *   Euclidean \n",
        "> *   Manhattan\n",
        "> *  LP Norm Distance Function\n",
        "\n",
        "* Angular Distance Functions\n",
        ">* Cosine Similarity"
      ]
    },
    {
      "metadata": {
        "id": "qAm6NfqFamzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">### Euclidean\n",
        "---\n",
        "Euclidean distance is a special case of Minkowski distance with $\\lambda=2$\n",
        "\n",
        "$Euclidean(\\vec{x}, \\vec{y}):= \\sqrt{\\sum_i(x_i-y_i)^2}$\n"
      ]
    },
    {
      "metadata": {
        "id": "_h3gndV8_LcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.spatial.distance as distance\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "def mins_helper(arr):\n",
        "    \n",
        "    indexed_used = []\n",
        "    for i in range(len(arr)):\n",
        "\n",
        "        row_min = np.argmin(arr[i])\n",
        "        if row_min in indexed_used:\n",
        "            new_row = arr[i]\n",
        "            new_row[row_min] = 999\n",
        "            row_min = np.argmin(new_row)     \n",
        "        \n",
        "        indexed_used.append(row_min)\n",
        "    \n",
        "    return indexed_used\n",
        "\n",
        "def euclidean_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: x and y images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.euclidean(v1, v2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "def euclidean_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v1.shape )\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v2.shape )\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    difference_sum = np.mean(np.amin(dist,axis=1))\n",
        "    \n",
        "    return difference_sum\n",
        "\n",
        "def euclidean_distance_modified_v2(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    d = mins_helper(dist)\n",
        "    sum = 0\n",
        "    for i in range(len(dist)):\n",
        "        sum += dist[i,d[i]]\n",
        "    return sum/len(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQCEm94jHrNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Manhattan\n",
        "---\n",
        "Manhattan distance is a special case of Minkowski distance with $\\lambda=1$\n",
        "\n",
        "$Manhattan(\\vec{x}, \\vec{y}):= \\sqrt{\\sum\\limits_i |x_i-y_i|}$\n",
        "\n",
        "Since flatten function is used, standard manhattan distance can be deceptive.\n",
        "\n",
        "A modified Manhattan distance will be more informative}."
      ]
    },
    {
      "metadata": {
        "id": "IO1gM_mIIikv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def manhattan_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cityblock(v1, v2)\n",
        "\n",
        "def manhattan_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: images\n",
        "        \n",
        "        Like modified euclidean, finds coordinates of black pixels, then\n",
        "        computes distance.\n",
        "        \n",
        "        \n",
        "        return manhattan distance between two images\n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'cityblock')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6DF2HCgzNoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "$CosineSimilarity(\\vec{x} , \\vec{y}) =\\dfrac{\\vec{x}.\\vec{y}}{||a||.||b||} $\n"
      ]
    },
    {
      "metadata": {
        "id": "oRr5_Pwm3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_distance_std(img1, img2):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cosine(v1, v2)\n",
        "\n",
        "\n",
        "def arccos_distance(img1,img2):\n",
        "    \n",
        "    cos_sim = 1 - cosine_distance_std(img1,img2)\n",
        "    \n",
        "    return (math.acos(cos_sim))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkH--BQHNsON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dynamic Time Warping"
      ]
    },
    {
      "metadata": {
        "id": "H8thSBeT3kZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dynamic Time Warping implementation\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "def dtw(img1,img2):\n",
        "    dist,path = fastdtw(img1,img2,dist = distance.jaccard)\n",
        "    \n",
        "    return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fV7cYZNuNuoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Canberra Distance"
      ]
    },
    {
      "metadata": {
        "id": "zjie1_iEDKNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def canberra_distance_std(img1, img2):\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.canberra(v1, v2)\n",
        "\n",
        "def canberra_distance_modified(img1, img2):\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'canberra')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZRBTXP-RJJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Other Standard Distance Functions"
      ]
    },
    {
      "metadata": {
        "id": "dbI2jCUbcLUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def braycurtis_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.braycurtis(v1, v2)\n",
        "\n",
        "def chebyshev_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.chebyshev(v1, v2)\n",
        "\n",
        "\n",
        "def correlation_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.correlation(v1, v2)\n",
        "\n",
        "def jensenshannon_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.jensenshannon(v1, v2)\n",
        "\n",
        "def hamming_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.hamming(v1, v2)\n",
        "\n",
        "\n",
        "\n",
        "def general_standard_distance(img1,img2, func):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return func(v1,v2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JTQJFthHTAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def distance_wrt_origin(img1,img2,distance_function):\n",
        "    \"\"\"\n",
        "      Calculates distance with respect to origin based on distance_function\n",
        "      \n",
        "      Extracts black pixels and calculate its coordinates, then sum distance to origin\n",
        "      \n",
        "      return both of the distances in a tuple like (v1_sum, v2_sum)\n",
        "      \n",
        "    \"\"\"\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    v1_sum = np.sum(distance.cdist(v1,[[0,0]], distance_function))\n",
        "    v2_sum = np.sum(distance.cdist(v2,[[0,0]], distance_function))\n",
        "    \n",
        "    \n",
        "    return v1_sum,v2_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2djM80TDImjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distance Functions Experiment Suite"
      ]
    },
    {
      "metadata": {
        "id": "UdwdLaLYamkt",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "4b84cbff-2f02-4e6a-b4fb-f39cb55e5260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\" }\n",
        "#@markdown Select characters and drawings to compute distances.\n",
        "\n",
        "\n",
        "\n",
        "character1 = 10 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing1 = 6 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "\n",
        "character2 = 16 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing2 = 7 #@param {type:\"slider\", min:0, max:18, step:1}\n",
        "\n",
        "img1 = new_latin[character1,drawing1]\n",
        "img2 = new_latin[character2,drawing2]\n",
        "\n",
        "#print(latin.shape)\n",
        "\n",
        "fig=plt.figure(figsize=(8, 8))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "imgplot = plt.imshow(img1)\n",
        "fig.add_subplot(1, 2, 2)\n",
        "imgplot = plt.imshow(img2)\n",
        "\n",
        "\n",
        "print(\"standard euclidean distance: \", euclidean_distance_std(img1,img2))\n",
        "print(\"modified euclidean distance: \", euclidean_distance_modified(img1,img2))\n",
        "print(\"modified euclidean distance_v2: \", euclidean_distance_modified_v2(img1,img2))\n",
        "print(\"standard manhattan distance: \",manhattan_distance_std(img1,img2))\n",
        "print(\"modified manhattan distance: \", manhattan_distance_modified(img1,img2))\n",
        "print(\"cosine similarity: \",cosine_distance_std(img1,img2))\n",
        "print(\"arccos similarity: \", arccos_distance(img1,img2))\n",
        "print(\"standard canberra distance: \", canberra_distance_std(img1,img2))\n",
        "print(\"modified canberra distance: \", canberra_distance_modified(img1,img2))\n",
        "\n",
        "print(\"dtw trial: \", dtw(img1, img2))\n",
        "\n",
        "v1_sum, v2_sum = distance_wrt_origin(img1,img2,\"euclidean\")\n",
        "print(\"Scores... img1: {0} and img2: {1} \".format(v1_sum,v2_sum))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard euclidean distance:  34.27827300200522\n",
            "modified euclidean distance:  16.84124135635496\n",
            "modified euclidean distance_v2:  16.94617858376173\n",
            "standard manhattan distance:  1175.0\n",
            "modified manhattan distance:  17.40237691001698\n",
            "cosine similarity:  0.8699666326855404\n",
            "arccos similarity:  1.4403936941243831\n",
            "standard canberra distance:  1175.0\n",
            "modified canberra distance:  0.18025534955257366\n",
            "dtw trial:  56.52432126378133\n",
            "Scores... img1: 34207.58285379298 and img2: 19872.09752317514 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lQCykxHdM-Ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ]
    },
    {
      "metadata": {
        "id": "Tya0Md9-D4JQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clasiffication runs according to basic non-parametric distance functions"
      ]
    },
    {
      "metadata": {
        "id": "TPovucPCSTO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1 )"
      ]
    },
    {
      "metadata": {
        "id": "ECbEKBF8KEtG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def classification_run(train_set, test_set, f_cost, ftype='cost'):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                costs[i,k,c] = f_cost(test_set[i,k],train_set[c])\n",
        "        stop = timeit.default_timer()\n",
        "        \n",
        "        print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "    \n",
        "    print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                             100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLQF-pm1QSX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_run_combined(train_set, test_set, ftype='cost', weights = [1,1,1], verbose = 1, func=[ euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs_1 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                if ex_arg is None:\n",
        "                    costs_1[i,k,c] = func[0](test_set[i,k],train_set[c])\n",
        "                    costs_2[i,k,c] = func[1](test_set[i,k],train_set[c])\n",
        "                    costs_3[i,k,c] = func[2](test_set[i,k],train_set[c])\n",
        "\n",
        "        stop = timeit.default_timer()\n",
        "        if verbose:\n",
        "            print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        predicted_class2 = []\n",
        "        predicted_class3 = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_1[i],1,axis=1))\n",
        "            predicted_class2.append(np.argpartition(costs_2[i],1,axis=1))\n",
        "            predicted_class3.append(np.argpartition(costs_3[i],1,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    flag=0\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            votes = np.zeros((n_test_class))\n",
        "            votes[predicted_class[i][j][0]]  += weights[0]\n",
        "            votes[predicted_class2[i][j][0]] += weights[1]\n",
        "            votes[predicted_class3[i][j][0]] += weights[2]\n",
        "\n",
        "            if np.argmax(votes) == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "            if flag: \n",
        "                flag -= 1\n",
        "                print(votes)\n",
        "    \n",
        "    if verbose:      \n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}\".format(i,class_scores[i], n_test_instances))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {2}\".format(correct,n_test_class * n_test_instances,100 * correct / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    return pcorrect\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMUk52RVdCpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def classification_run_combined2(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    costs[i,k,c]  = func[0](test_set[i,k],train_set[c])\n",
        "                    costs2[i,k,c] = func[1](test_set[i,k], train_set[c])\n",
        "                    costs3[i,k,c] = func[2](test_set[i,k], train_set[c])\n",
        "\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3vSXR_ESYDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2)"
      ]
    },
    {
      "metadata": {
        "id": "QPw79oXanXDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def save_costs():\n",
        "    np.save(\"costs_dictionary\", costs_dict)\n",
        "\n",
        "def load_costs():\n",
        "    return np.load(\"costs_dictionary\").item()  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7nz5EM_BKSw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "costs_dict = load_costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xeidI3FDSi6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_run_combined2_general(train_set, test_set, ftype='cost', weights = [], verbose = 1, \n",
        "                                         func = [distance.euclidean, distance.cityblock, distance.cosine],\n",
        "                                         custom_funcs = [], dic = costs_dict):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    #if not costs_dict:\n",
        "    #    costs_dict = load_costs()\n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    if custom_funcs == []:\n",
        "        n_function = len(func)\n",
        "    else:\n",
        "        n_function = len(custom_funcs)\n",
        "        \n",
        "    if len(weights) == 0:\n",
        "        if custom_funcs == []:\n",
        "            weights = [1 for _ in range(len(func))]\n",
        "        else:\n",
        "            weights = [1 for _ in range(len(custom_funcs))]\n",
        "    \n",
        "    costs  = np.zeros((n_function,n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "\n",
        "    \n",
        "    for f in range(n_function):\n",
        "        start = timeit.default_timer()\n",
        "        if custom_funcs == []:\n",
        "            if func[f].__name__ in dic:\n",
        "                #print(func[f].__name__)\n",
        "                costs[f] = dic[func[f].__name__]\n",
        "                continue\n",
        "        else:\n",
        "            if custom_funcs[f].__name__ in dic:\n",
        "                costs[f] = dic[custom_funcs[f].__name__]\n",
        "                continue\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    if custom_funcs == []:\n",
        "                        for _i in range(len(train_set[c])):\n",
        "                            costs[f,i,k,c]  += general_standard_distance(test_set[i,k], train_set[c,_i], func[f])\n",
        "\n",
        "                    else:\n",
        "                        for _i in range(len(train_set[c])):\n",
        "                            costs[f,i,k,c]  += custom_funcs[f](test_set[i,k],train_set[c,_i])\n",
        "                        \n",
        "                        \n",
        "        if custom_funcs == []:\n",
        "            dic[func[f].__name__] = costs[f]\n",
        "        else:\n",
        "            dic[custom_funcs[f].__name__] = costs[f]\n",
        "        stop = timeit.default_timer()\n",
        "        if(verbose):\n",
        "            print(\"Test function: {0}/{2} completed. Time: {1} sec. \".format(f+1, stop - start, n_function, ))\n",
        "    for f in range(n_function):\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[f,i,k] = costs[f,i,k]/np.max(costs[f,i,k])\n",
        "                \n",
        "\n",
        "    costs_res = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for f in range(n_function):\n",
        "        costs_res += weights[f] * costs[f] \n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "    \n",
        "    top1 = 100 * correct / (n_test_class * n_test_instances)\n",
        "    top2 = 100 * correct2 / (n_test_class * n_test_instances)\n",
        "    top3 = 100 * correct3 / (n_test_class * n_test_instances)\n",
        "\n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {2}, Top2 -: {3}/{1} = {4}, Top3 -: {5}/{1} = {6}\".format(correct,n_test_class * n_test_instances,top1,correct2,top2,correct3, top3))\n",
        "    perror = 100 - top1\n",
        "    \n",
        "    return (top1, top2, top3)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p0_LypVjktVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = [distance.braycurtis, distance.jensenshannon, distance.cosine, distance.correlation,\n",
        "     distance.yule, distance.euclidean, distance.russellrao, distance.canberra, \n",
        "     distance.chebyshev, distance.jaccard, distance.dice, distance.rogerstanimoto, distance.kulsinski]\n",
        "w = np.random.uniform(0,1,len(f))\n",
        "w = w/np.sum(w)\n",
        "c= {}\n",
        "top1,top2,top3 = classification_run_combined2_general(latin_samples, new_latin, verbose = 1, func = f, weights=w, dic = c)\n",
        "print(\"Weights: \", w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5eeUNb12Q0rN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fas = [euclidean_distance_modified, canberra_distance_modified]\n",
        "w = np.random.uniform(0,1,len(fas))\n",
        "w = w/np.sum(w)\n",
        "w = [0.26476642, 0.73523358]\n",
        "c = {}\n",
        "top1,top2,top3 = classification_run_combined2_general(latin_samples2, new_latin2, verbose = 1, weights=w, custom_funcs = fas, dic = c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7oz6szXb7HM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples, new_alph = get_sample(latin, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCA0RDSUVdVj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = [distance.euclidean]\n",
        "c = {}\n",
        "top1, top2, top3 = classification_run_combined2_general(samples,new_alph,verbose=1,func=f, dic = c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wLjR4g0Supa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "cust_funcs = [euclidean_distance_modified,canberra_distance_modified]\n",
        "\n",
        "funcs = [distance.jaccard]\n",
        "\n",
        "over_max = 0\n",
        "single_max = (0,0,0)\n",
        "single_max_func = funcs[0]\n",
        "\n",
        "c = {}\n",
        "\n",
        "for i in funcs:\n",
        "    res = classification_run_combined2_general(latin_samples2, new_latin2, verbose=0, weights=[1], func= [i], dic=c)\n",
        "    if(res[0] > single_max[0]):\n",
        "        single_max = res\n",
        "        single_max_func = i\n",
        "\n",
        "print(\"Single distance maximum score: {0} with {1} \\n\\n\".format(single_max, single_max_func.__name__))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4TLh2M07YJVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = (0,0,0)\n",
        "best_weights = []\n",
        "turn = 0\n",
        "max_iteration = 10000\n",
        "\n",
        "for i in range(1,max_iteration):\n",
        "    start = timeit.default_timer()\n",
        "    w = np.random.uniform(1,10,len(funcs))\n",
        "    w = w/np.sum(w)\n",
        "    top1,top2,top3 = classification_run_combined2_general(latin_samples2, new_latin2, verbose = 0, weights=w, func = funcs, custom_funcs = [], dic=c)\n",
        "    if(top1 > single_max[0]):\n",
        "        over_max += 1\n",
        "    #print(\"{0}/1000 iteration finished. Score: {1}. Weights: {2}\".format(i,(top1,top2,top3),w))\n",
        "    if top1 > best_score[0]:\n",
        "        print(\"###############Found###############\")\n",
        "        print(\"Old Score: {0}, New Score: {1}, Old Weights: {2}, New Weights: {3}\".format(best_score,(top1,top2,top3),best_weights,w))\n",
        "        best_score = (top1,top2,top3)\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    #print(\"Remaining time: {0} \\n\\n\".format((max_iteration-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8lTcL97Sfv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Runs:"
      ]
    },
    {
      "metadata": {
        "id": "aERN-ZQRdX6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pcorrect, costs_euclidean_modified, costs_cosine_std = classification_run_combined2(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3iaygPGcOHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.argmin(costs_euclidean_modified[3],axis=1))\n",
        "print(\"\\n \\n \\n\")\n",
        "print(costs_euclidean_modified[3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyxwoRST2kfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.uniform(0,3,3)\n",
        "    x = classification_run_combined(latin_samples,new_latin, weights = w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6J4kI2ZsXMMT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    start = timeit.default_timer()\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.standard_t(10,3)\n",
        "    x , _ , _ = classification_run_combined2(latin_samples,new_latin, weights=w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i, \". weights: \",w, \" score:\",x)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    print(\"{0}/100 finished. Remaining time {1}\".format(i, (100-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJc9aQMWQPMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5RKn3ZIQOgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_run(latin_samples, new_latin, manhattan_distance_modified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JC-hpKubaRAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x , y, z = classification_run_combined2(latin_samples, new_latin, _costs = costs_euclidean_modified, _costs2 = costs_cosine_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTDp11EHj1G5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classification_run_combined(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsj4EjROUvdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[general_standard_distance, general_standard_distance, general_standard_distance], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9U_99GEUtsY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### does t-SNE work?\n",
        "\n",
        "It predicts  same class for  every test instances.  FIX"
      ]
    },
    {
      "metadata": {
        "id": "c-cKDR9RUsyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def classification_run_tsne(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    \n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    _tsne = TSNE(n_components=2)\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    test_tsne, train_tsne = _tsne.fit_transform(test_set[i,k]), _tsne.fit_transform(train_set[c])\n",
        "                    costs[i,k,c]  = func[0](test_tsne, train_tsne)\n",
        "                    costs2[i,k,c] = func[1](test_tsne, train_tsne)\n",
        "                    costs3[i,k,c] = func[2](test_tsne, train_tsne)\n",
        "                    \n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "    plt.show()\n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlFQKZVHWBbi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "asd = new_latin[0:2]\n",
        "x ,y ,z = classification_run_tsne(latin_samples, asd,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}