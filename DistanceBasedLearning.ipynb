{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistanceBasedLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Ee_PILA4IJWN",
        "peA9CqHzIgyR",
        "ZBGpCUBudPfM",
        "ftfT02r3X1Sw",
        "qAm6NfqFamzz",
        "eQCEm94jHrNg",
        "K6DF2HCgzNoO",
        "YkH--BQHNsON",
        "fV7cYZNuNuoS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Ee_PILA4IJWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "lFcQMRGKIR7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -r CMANN\n",
        "#!git clone https://github.com/Orkun-tanik/CMANN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "peA9CqHzIgyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Omniglot"
      ]
    },
    {
      "metadata": {
        "id": "48OyelLWJQYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The Omniglot* dataset is a collection of 1623 hand drawn characters from 50 alphabets. For every character there are just 20 examples, each drawn by a different person at resolution 105x105."
      ]
    },
    {
      "metadata": {
        "id": "rJjxbj1QJT4_",
        "colab_type": "code",
        "outputId": "f5a5323d-9619-4e88-d6ec-ff296fff4f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#!unzip CMANN/images_evaluation.zip\n",
        "#!unzip CMANN/images_background.zip\n",
        "\n",
        "\"\"\"  Do not execute again!!  \"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Do not execute again!!  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "K1GOfegpNEtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyQ4fqrQdBVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_origin(image):\n",
        "    \"\"\"\n",
        "       Image: Black pixels labeled as True\n",
        "        \n",
        "       It moves the image towards the origin,\n",
        "                returns new_image and black pixels coordinates array: (new_image,blacks)  \n",
        "                \n",
        "    \"\"\"\n",
        "\n",
        "    x,y = image.shape\n",
        "    xshift = x\n",
        "    yshift = y\n",
        "\n",
        "    blacks = []\n",
        "\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j))\n",
        "                if i<xshift:\n",
        "                    xshift = i\n",
        "                if j<yshift:\n",
        "                    yshift = j\n",
        "\n",
        "    new_image = np.zeros(shape=(x,y))\n",
        "\n",
        "    for i in range(len(blacks)):\n",
        "        (a,b) = blacks[i]\n",
        "        blacks[i] = (a-xshift, b-yshift)\n",
        "        new_image[a-xshift][b-yshift] = 1\n",
        "    \n",
        "    blacks = np.array(blacks)\n",
        "\n",
        "    return (new_image, blacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Mli7B2nJljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = \"\"\n",
        "train_path = os.path.join(data_path,'images_background')\n",
        "validation_path = os.path.join(data_path,'images_evaluation')\n",
        "\n",
        "\n",
        "\n",
        "def load_images_from_directory(path):\n",
        "    X=[]\n",
        "\n",
        "    ## We load every alphabet seperately and append that to one tensor\n",
        "    for alphabet in os.listdir(path):\n",
        "        #print(\"loading alphabet: \" + alphabet)\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        \n",
        "        ## Each character in alphabet is in a separate folder\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            #print(\" + letter: \" + letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "        \n",
        "            \n",
        "            if not os.path.isdir(letter_path):\n",
        "                continue\n",
        "\n",
        "            ## Read every image in this directory\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = mpimg.imread(image_path)\n",
        "                #print(image)\n",
        "                \n",
        "                \n",
        "                #TODO: recreate images with black pixels coordinate values\n",
        "                \n",
        "                \n",
        "                ### Image preprocessing!\n",
        "                #image = image/255\n",
        "                #image = 1-image\n",
        "                \n",
        "                image = np.logical_not(image)\n",
        "                #print(\"prepocessing image...\")\n",
        "                \n",
        "                new_image, _ = to_origin(image)\n",
        "                \n",
        "                \n",
        "                #print(\"done.\")\n",
        "                #print(image)           \n",
        "                \n",
        "                category_images.append(new_image)\n",
        "            \n",
        "            try:\n",
        "                X.append(np.array(category_images))\n",
        "            #edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "    \n",
        "    X = np.array(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gwvm2R90PCFK",
        "colab_type": "code",
        "outputId": "304c614a-0b1b-4ecb-ac46-f8c9887535bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Loading training set\")\n",
        "#Xtrain = load_images_from_directory(train_path)\n",
        "#print(Xtrain.shape)\n",
        "\n",
        "print(\"Now loading evaluation set\")\n",
        "#Xval = load_images_from_directory(validation_path)\n",
        "#print(Xval.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training set\n",
            "Now loading evaluation set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jHsxmnlPNgm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.save('Xtrain.npy', Xtrain)\n",
        "#np.save('Xval.npy', Xval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEaVm3uTuTpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Xtrain = np.load(\"Xtrain.npy\")\n",
        "#Xval = np.load(\"Xval.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Lzrn79ENmN_",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "f304a4d4-d115-42a5-c1c2-c0dcc40ab9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"#@title Example Image to be displayed { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 270 #@param {type:\"integer\"}\n",
        "drawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "\n",
        "if (image_set == 'Xval'):\n",
        "    imgplot = plt.imshow(Xval[character,drawing])\n",
        "else:\n",
        "    imgplot = plt.imshow(Xtrain[character,drawing])\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#@title Example Image to be displayed { run: \"auto\" }\\nimport matplotlib.pyplot as plt\\n\\ncharacter = 270 #@param {type:\"integer\"}\\ndrawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\\nimage_set = \\'Xtrain\\' #@param [\"Xval\", \"Xtrain\"]\\n\\nif (image_set == \\'Xval\\'):\\n    imgplot = plt.imshow(Xval[character,drawing])\\nelse:\\n    imgplot = plt.imshow(Xtrain[character,drawing])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "P2YL-GHSV2zL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Latin Images"
      ]
    },
    {
      "metadata": {
        "id": "Ct5DyzmNWjc3",
        "colab_type": "code",
        "outputId": "d85e9348-ebe0-4ba4-acec-2aa6621f50df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "latin_path = \"Latin\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "latin = load_images_from_directory(latin_path)\n",
        "print(latin.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(26, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8lU37kuPT_j",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "1312e071-4d4c-4f42-eeaf-db76b3d5304a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin[character,drawing])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9424a00f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "eiOL3XzPQE6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def black_pixels(image):\n",
        "    \"\"\"\n",
        "       returns black pixel coordinates of image, array-like\n",
        "    \"\"\"\n",
        "    \n",
        "    x,y = image.shape\n",
        "    blacks = []\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j)) \n",
        "\n",
        "\n",
        "\n",
        "    return np.array(blacks)\n",
        "\n",
        "# Extract random samples from each character of given alphabet\n",
        "\n",
        "def get_sample(alphabet):\n",
        "    \n",
        "    \"\"\"\n",
        "        alphabet numpy array [size, drawing, 105, 105]\n",
        "    \n",
        "        returns samples and altered alphabet\n",
        "    \"\"\"\n",
        "    character_count, drawing_count, _, _ = alphabet.shape\n",
        "    samples = []\n",
        "    new_alphabet = []    \n",
        "    for i in range(character_count):\n",
        "        rand = np.random.randint(0,drawing_count)\n",
        "        samples.append(alphabet[i,rand])\n",
        "        new_alphabet.append(np.delete(alphabet[i], rand, 0))  \n",
        "    \n",
        "    \n",
        "    samples = np.array(samples)\n",
        "    new_alphabet = np.array(new_alphabet)\n",
        "    \n",
        "    return samples, new_alphabet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmQanN0cR1L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "latin_samples, new_latin = get_sample(latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEtqxXxMU9LV",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "526b7005-d3c8-4842-ad40-7cb1fd8771e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 3 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin_samples[character])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9421f64e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IIxwKGRMWK3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***These sample latin images will be used for testing distance functions. ***"
      ]
    },
    {
      "metadata": {
        "id": "ZBGpCUBudPfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Greek Images\n"
      ]
    },
    {
      "metadata": {
        "id": "zbwc4pR9dasc",
        "colab_type": "code",
        "outputId": "ee256f6e-566a-4b78-93ad-2775479539b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "greek_path = \"Greek\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "greek = load_images_from_directory(greek_path)\n",
        "print(greek.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(24, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FBQWGFEdyf5",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "2fd9a8e4-7f87-4503-8469-24416bfead7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek[character,drawing])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa942170d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_wl7kyGMd6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "greek_samples, new_greek = get_sample(greek)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVN57oPWd_KJ",
        "colab_type": "code",
        "outputId": "9e8ccb7d-22d2-49e3-924e-66e3d8d2794a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 16 #@param {type:\"slider\", min:0, max:23, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek_samples[character])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa9421597f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3u3QOMrMWgkJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*In this section,  there are experiments of distance functions for one-shot learning . Follow the headers for distance functions properties.*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ftfT02r3X1Sw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elementary Distance Functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "* Minkowski Family\n",
        "> *   Euclidean \n",
        "> *   Manhattan\n",
        "> *  LP Norm Distance Function\n",
        "\n",
        "* Angular Distance Functions\n",
        ">* Cosine Similarity"
      ]
    },
    {
      "metadata": {
        "id": "qAm6NfqFamzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">### Euclidean\n",
        "---\n",
        "Euclidean distance is a special case of Minkowski distance with $\\lambda=2$\n",
        "\n",
        "$Euclidean(\\vec{x}, \\vec{y}):= \\sqrt{\\sum_i(x_i-y_i)^2}$\n"
      ]
    },
    {
      "metadata": {
        "id": "_h3gndV8_LcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.spatial.distance as distance\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "def mins_helper(arr):\n",
        "    \n",
        "    indexed_used = []\n",
        "    for i in range(len(arr)):\n",
        "\n",
        "        row_min = np.argmin(arr[i])\n",
        "        if row_min in indexed_used:\n",
        "            new_row = arr[i]\n",
        "            new_row[row_min] = 999\n",
        "            row_min = np.argmin(new_row)     \n",
        "        \n",
        "        indexed_used.append(row_min)\n",
        "    \n",
        "    return indexed_used\n",
        "\n",
        "def euclidean_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: x and y images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.euclidean(v1, v2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "def euclidean_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v1.shape )\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v2.shape )\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    difference_sum = np.mean(np.amin(dist,axis=1))\n",
        "    \n",
        "    return difference_sum\n",
        "\n",
        "def euclidean_distance_modified_v2(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    d = mins_helper(dist)\n",
        "    sum = 0\n",
        "    for i in range(len(dist)):\n",
        "        sum += dist[i,d[i]]\n",
        "    return sum/len(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQCEm94jHrNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Manhattan\n",
        "---\n",
        "Manhattan distance is a special case of Minkowski distance with $\\lambda=1$\n",
        "\n",
        "$Manhattan(\\vec{x}, \\vec{y}):= \\sqrt{\\sum\\limits_i |x_i-y_i|}$\n",
        "\n",
        "Since flatten function is used, standard manhattan distance can be deceptive.\n",
        "\n",
        "A modified Manhattan distance will be more informative}."
      ]
    },
    {
      "metadata": {
        "id": "IO1gM_mIIikv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def manhattan_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cityblock(v1, v2)\n",
        "\n",
        "def manhattan_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: images\n",
        "        \n",
        "        Like modified euclidean, finds coordinates of black pixels, then\n",
        "        computes distance.\n",
        "        \n",
        "        \n",
        "        return manhattan distance between two images\n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'cityblock')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6DF2HCgzNoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "$CosineSimilarity(\\vec{x} , \\vec{y}) =\\dfrac{\\vec{x}.\\vec{y}}{||a||.||b||} $\n"
      ]
    },
    {
      "metadata": {
        "id": "oRr5_Pwm3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_distance_std(img1, img2):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cosine(v1, v2)\n",
        "\n",
        "\n",
        "def arccos_distance(img1,img2):\n",
        "    \n",
        "    cos_sim = 1 - cosine_distance_std(img1,img2)\n",
        "    \n",
        "    return (math.acos(cos_sim))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkH--BQHNsON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dynamic Time Warping"
      ]
    },
    {
      "metadata": {
        "id": "H8thSBeT3kZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dynamic Time Warping implementation\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "def dtw(img1,img2):\n",
        "    dist,path = fastdtw(img1,img2,dist = distance.jaccard)\n",
        "    \n",
        "    return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fV7cYZNuNuoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Canberra Distance"
      ]
    },
    {
      "metadata": {
        "id": "zjie1_iEDKNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def canberra_distance_std(img1, img2):\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.canberra(v1, v2)\n",
        "\n",
        "def canberra_distance_modified(img1, img2):\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'canberra')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZRBTXP-RJJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Other Standard Distance Functions"
      ]
    },
    {
      "metadata": {
        "id": "dbI2jCUbcLUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def braycurtis_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.braycurtis(v1, v2)\n",
        "\n",
        "def chebyshev_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.chebyshev(v1, v2)\n",
        "\n",
        "\n",
        "def correlation_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.correlation(v1, v2)\n",
        "\n",
        "def jensenshannon_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.jensenshannon(v1, v2)\n",
        "\n",
        "def hamming_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.hamming(v1, v2)\n",
        "\n",
        "\n",
        "\n",
        "def general_standard_distance(img1,img2, func):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return func(v1,v2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JTQJFthHTAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def distance_wrt_origin(img1,img2,distance_function):\n",
        "    \"\"\"\n",
        "      Calculates distance with respect to origin based on distance_function\n",
        "      \n",
        "      Extracts black pixels and calculate its coordinates, then sum distance to origin\n",
        "      \n",
        "      return both of the distances in a tuple like (v1_sum, v2_sum)\n",
        "      \n",
        "    \"\"\"\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    v1_sum = np.sum(distance.cdist(v1,[[0,0]], distance_function))\n",
        "    v2_sum = np.sum(distance.cdist(v2,[[0,0]], distance_function))\n",
        "    \n",
        "    \n",
        "    return v1_sum,v2_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2djM80TDImjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distance Functions Experiment Suite"
      ]
    },
    {
      "metadata": {
        "id": "UdwdLaLYamkt",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "4b84cbff-2f02-4e6a-b4fb-f39cb55e5260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\" }\n",
        "#@markdown Select characters and drawings to compute distances.\n",
        "\n",
        "\n",
        "\n",
        "character1 = 10 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing1 = 6 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "\n",
        "character2 = 16 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing2 = 7 #@param {type:\"slider\", min:0, max:18, step:1}\n",
        "\n",
        "img1 = new_latin[character1,drawing1]\n",
        "img2 = new_latin[character2,drawing2]\n",
        "\n",
        "#print(latin.shape)\n",
        "\n",
        "fig=plt.figure(figsize=(8, 8))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "imgplot = plt.imshow(img1)\n",
        "fig.add_subplot(1, 2, 2)\n",
        "imgplot = plt.imshow(img2)\n",
        "\n",
        "\n",
        "print(\"standard euclidean distance: \", euclidean_distance_std(img1,img2))\n",
        "print(\"modified euclidean distance: \", euclidean_distance_modified(img1,img2))\n",
        "print(\"modified euclidean distance_v2: \", euclidean_distance_modified_v2(img1,img2))\n",
        "print(\"standard manhattan distance: \",manhattan_distance_std(img1,img2))\n",
        "print(\"modified manhattan distance: \", manhattan_distance_modified(img1,img2))\n",
        "print(\"cosine similarity: \",cosine_distance_std(img1,img2))\n",
        "print(\"arccos similarity: \", arccos_distance(img1,img2))\n",
        "print(\"standard canberra distance: \", canberra_distance_std(img1,img2))\n",
        "print(\"modified canberra distance: \", canberra_distance_modified(img1,img2))\n",
        "\n",
        "print(\"dtw trial: \", dtw(img1, img2))\n",
        "\n",
        "v1_sum, v2_sum = distance_wrt_origin(img1,img2,\"euclidean\")\n",
        "print(\"Scores... img1: {0} and img2: {1} \".format(v1_sum,v2_sum))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard euclidean distance:  34.27827300200522\n",
            "modified euclidean distance:  16.84124135635496\n",
            "modified euclidean distance_v2:  16.94617858376173\n",
            "standard manhattan distance:  1175.0\n",
            "modified manhattan distance:  17.40237691001698\n",
            "cosine similarity:  0.8699666326855404\n",
            "arccos similarity:  1.4403936941243831\n",
            "standard canberra distance:  1175.0\n",
            "modified canberra distance:  0.18025534955257366\n",
            "dtw trial:  56.52432126378133\n",
            "Scores... img1: 34207.58285379298 and img2: 19872.09752317514 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lQCykxHdM-Ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ]
    },
    {
      "metadata": {
        "id": "Tya0Md9-D4JQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clasiffication runs according to basic non-parametric distance functions"
      ]
    },
    {
      "metadata": {
        "id": "TPovucPCSTO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1 )"
      ]
    },
    {
      "metadata": {
        "id": "ECbEKBF8KEtG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def classification_run(train_set, test_set, f_cost, ftype='cost'):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                costs[i,k,c] = f_cost(test_set[i,k],train_set[c])\n",
        "        stop = timeit.default_timer()\n",
        "        \n",
        "        print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "    \n",
        "    print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                             100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLQF-pm1QSX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_run_combined(train_set, test_set, ftype='cost', weights = [1,1,1], verbose = 1, func=[ euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs_1 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                if ex_arg is None:\n",
        "                    costs_1[i,k,c] = func[0](test_set[i,k],train_set[c])\n",
        "                    costs_2[i,k,c] = func[1](test_set[i,k],train_set[c])\n",
        "                    costs_3[i,k,c] = func[2](test_set[i,k],train_set[c])\n",
        "\n",
        "        stop = timeit.default_timer()\n",
        "        if verbose:\n",
        "            print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        predicted_class2 = []\n",
        "        predicted_class3 = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_1[i],1,axis=1))\n",
        "            predicted_class2.append(np.argpartition(costs_2[i],1,axis=1))\n",
        "            predicted_class3.append(np.argpartition(costs_3[i],1,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    flag=0\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            votes = np.zeros((n_test_class))\n",
        "            votes[predicted_class[i][j][0]]  += weights[0]\n",
        "            votes[predicted_class2[i][j][0]] += weights[1]\n",
        "            votes[predicted_class3[i][j][0]] += weights[2]\n",
        "\n",
        "            if np.argmax(votes) == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "            if flag: \n",
        "                flag -= 1\n",
        "                print(votes)\n",
        "    \n",
        "    if verbose:      \n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}\".format(i,class_scores[i], n_test_instances))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {2}\".format(correct,n_test_class * n_test_instances,100 * correct / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    return pcorrect\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMUk52RVdCpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def classification_run_combined2(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    costs[i,k,c]  = func[0](test_set[i,k],train_set[c])\n",
        "                    costs2[i,k,c] = func[1](test_set[i,k], train_set[c])\n",
        "                    costs3[i,k,c] = func[2](test_set[i,k], train_set[c])\n",
        "\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3vSXR_ESYDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2)"
      ]
    },
    {
      "metadata": {
        "id": "xeidI3FDSi6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_run_combined2_general(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [distance.euclidean, distance.cityblock, distance.cosine]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    n_function = len(func)\n",
        "    \n",
        "    costs  = np.zeros((n_function,n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for f in range(n_function):\n",
        "            for i in range(n_test_class):\n",
        "                start = timeit.default_timer()\n",
        "                for k in range(n_test_instances):\n",
        "                    for c in range(n_train):\n",
        "                        costs[f,i,k,c]  = general_standard_distance(test_set[i,k], train_set[c], func[f])\n",
        "\n",
        "\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test function: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(f+1, stop - start, n_test_class, (stop-start)*(n_test_class-f-1)))\n",
        "        for f in range(n_function):\n",
        "            for i in range(n_test_class):\n",
        "                for k in range(n_test_instances):\n",
        "                    costs[f,i,k] = costs[f,i,k]/np.max(costs[f,i,k])\n",
        "\n",
        "    costs_res = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for f in range(n_function):\n",
        "        costs_res += weights[f] * costs[f] \n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "    \n",
        "    top1 = 100 * correct / (n_test_class * n_test_instances)\n",
        "    top2 = 100 * correct2 / (n_test_class * n_test_instances)\n",
        "    top3 = 100 * correct3 / (n_test_class * n_test_instances)\n",
        "\n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {2}, Top2 -: {3}/{1} = {4}, Top3 -: {5}/{1} = {6}\".format(correct,n_test_class * n_test_instances,top1,correct2,top2,correct3, top3))\n",
        "    perror = 100 - top1\n",
        "    \n",
        "    return (top1, top2, top3)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5eeUNb12Q0rN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "151c2aa0-1541-4477-d1cb-ce16c474ed31"
      },
      "cell_type": "code",
      "source": [
        "f = [distance.yule, distance.braycurtis, distance.euclidean]\n",
        "\n",
        "top1,top2,top3 = classification_run_combined2_general(latin_samples, new_latin, verbose = 1, weights=[1., 0, 0.], func = f)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test function: 1/26 completed. Time: 0.06528557901037857 sec. Estimated remaining time: 1.6321394752594642 sec\n",
            "Test function: 2/26 completed. Time: 0.03447176000918262 sec. Estimated remaining time: 0.8273222402203828 sec\n",
            "Test function: 3/26 completed. Time: 0.025624548987252638 sec. Estimated remaining time: 0.5893646267068107 sec\n",
            " Class 0 : Top1 correct: 0.0/19, Top2 correct: 1.0/19, Top3 correct: 1.0/19\n",
            " Class 1 : Top1 correct: 9.0/19, Top2 correct: 9.0/19, Top3 correct: 10.0/19\n",
            " Class 2 : Top1 correct: 12.0/19, Top2 correct: 17.0/19, Top3 correct: 19.0/19\n",
            " Class 3 : Top1 correct: 14.0/19, Top2 correct: 15.0/19, Top3 correct: 16.0/19\n",
            " Class 4 : Top1 correct: 2.0/19, Top2 correct: 4.0/19, Top3 correct: 4.0/19\n",
            " Class 5 : Top1 correct: 0.0/19, Top2 correct: 2.0/19, Top3 correct: 2.0/19\n",
            " Class 6 : Top1 correct: 8.0/19, Top2 correct: 10.0/19, Top3 correct: 11.0/19\n",
            " Class 7 : Top1 correct: 8.0/19, Top2 correct: 10.0/19, Top3 correct: 13.0/19\n",
            " Class 8 : Top1 correct: 0.0/19, Top2 correct: 3.0/19, Top3 correct: 7.0/19\n",
            " Class 9 : Top1 correct: 4.0/19, Top2 correct: 10.0/19, Top3 correct: 11.0/19\n",
            " Class 10 : Top1 correct: 1.0/19, Top2 correct: 2.0/19, Top3 correct: 8.0/19\n",
            " Class 11 : Top1 correct: 4.0/19, Top2 correct: 14.0/19, Top3 correct: 15.0/19\n",
            " Class 12 : Top1 correct: 5.0/19, Top2 correct: 6.0/19, Top3 correct: 7.0/19\n",
            " Class 13 : Top1 correct: 6.0/19, Top2 correct: 9.0/19, Top3 correct: 10.0/19\n",
            " Class 14 : Top1 correct: 5.0/19, Top2 correct: 8.0/19, Top3 correct: 12.0/19\n",
            " Class 15 : Top1 correct: 12.0/19, Top2 correct: 16.0/19, Top3 correct: 18.0/19\n",
            " Class 16 : Top1 correct: 15.0/19, Top2 correct: 16.0/19, Top3 correct: 18.0/19\n",
            " Class 17 : Top1 correct: 3.0/19, Top2 correct: 4.0/19, Top3 correct: 8.0/19\n",
            " Class 18 : Top1 correct: 3.0/19, Top2 correct: 6.0/19, Top3 correct: 6.0/19\n",
            " Class 19 : Top1 correct: 7.0/19, Top2 correct: 8.0/19, Top3 correct: 10.0/19\n",
            " Class 20 : Top1 correct: 5.0/19, Top2 correct: 7.0/19, Top3 correct: 10.0/19\n",
            " Class 21 : Top1 correct: 8.0/19, Top2 correct: 8.0/19, Top3 correct: 9.0/19\n",
            " Class 22 : Top1 correct: 1.0/19, Top2 correct: 1.0/19, Top3 correct: 1.0/19\n",
            " Class 23 : Top1 correct: 1.0/19, Top2 correct: 2.0/19, Top3 correct: 2.0/19\n",
            " Class 24 : Top1 correct: 1.0/19, Top2 correct: 2.0/19, Top3 correct: 3.0/19\n",
            " Class 25 : Top1 correct: 0.0/19, Top2 correct: 0.0/19, Top3 correct: 2.0/19\n",
            "Total: Top1 -: 134.0/494 = 27.125506072874494, Top2 -: 190.0/494 = 38.46153846153846, Top3 -: 233.0/494 = 47.16599190283401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_wLjR4g0Supa",
        "colab_type": "code",
        "outputId": "eb40ca1e-974b-4e49-810e-6813bbd9875b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3400
        }
      },
      "cell_type": "code",
      "source": [
        "best_score = (0,0,0)\n",
        "best_weights = []\n",
        "turn = 0\n",
        "max_iteration = 1000\n",
        "funcs1 = [distance.braycurtis, distance.euclidean, distance.jensenshannon, distance.cosine]\n",
        "\n",
        "funcs = [distance.cosine, distance.braycurtis, distance.euclidean]\n",
        "\n",
        "over_max = 0\n",
        "single_max = (0,0,0)\n",
        "single_max_func = funcs[0]\n",
        "\n",
        "for i in funcs:\n",
        "    res = classification_run_combined2_general(latin_samples, new_latin, verbose=0, weights=[1], func=[i])\n",
        "    if(res[0] > single_max[0]):\n",
        "        single_max = res\n",
        "        single_max_func = i\n",
        "\n",
        "print(\"Single distance maximum score: {0} with {1} \\n\\n\".format(single_max, single_max_func.__name__))\n",
        "\n",
        "for i in range(1,max_iteration):\n",
        "    start = timeit.default_timer()\n",
        "    w = np.random.uniform(0,0.5,len(funcs))\n",
        "    w = w/np.sum(w)\n",
        "    top1,top2,top3 = classification_run_combined2_general(latin_samples, new_latin, verbose = 0, weights=w, func = funcs)\n",
        "    if(top1 > single_max[0]):\n",
        "        over_max += 1\n",
        "    print(\"{0}/1000 iteration finished. Score: {1}. Weights: {2}\".format(i,(top1,top2,top3),w))\n",
        "    if top1 > best_score[0]:\n",
        "        print(\"###############Found###############\")\n",
        "        print(\"Old Score: {0}, New Score: {1}, Old Weights: {2}, New Weights: {3}\".format(best_score,(top1,top2,top3),best_weights,w))\n",
        "        best_score = (top1,top2,top3)\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    print(\"Remaining time: {0} \\n\\n\".format((max_iteration-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))\n",
        "print(\"Single\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single distance maximum score: (31.17408906882591, 44.12955465587044, 50.80971659919028) with braycurtis \n",
            "\n",
            "\n",
            "1/1000 iteration finished. Score: (31.17408906882591, 42.91497975708502, 49.797570850202426). Weights: [0.0666462  0.37807447 0.55527933]\n",
            "###############Found###############\n",
            "Old Score: (0, 0, 0), New Score: (31.17408906882591, 42.91497975708502, 49.797570850202426), Old Weights: [], New Weights: [0.0666462  0.37807447 0.55527933]\n",
            "Remaining time: 2875.659255777544 \n",
            "\n",
            "\n",
            "2/1000 iteration finished. Score: (29.149797570850204, 40.08097165991903, 48.38056680161943). Weights: [0.1064145  0.18392035 0.70966515]\n",
            "Remaining time: 2785.392669024586 \n",
            "\n",
            "\n",
            "3/1000 iteration finished. Score: (31.983805668016196, 45.54655870445344, 51.61943319838057). Weights: [0.01729121 0.84797527 0.13473352]\n",
            "###############Found###############\n",
            "Old Score: (31.17408906882591, 42.91497975708502, 49.797570850202426), New Score: (31.983805668016196, 45.54655870445344, 51.61943319838057), Old Weights: [0.0666462  0.37807447 0.55527933], New Weights: [0.01729121 0.84797527 0.13473352]\n",
            "Remaining time: 2900.575161771616 \n",
            "\n",
            "\n",
            "4/1000 iteration finished. Score: (31.57894736842105, 43.7246963562753, 50.40485829959514). Weights: [0.61400753 0.23683408 0.14915839]\n",
            "Remaining time: 2740.337680887751 \n",
            "\n",
            "\n",
            "5/1000 iteration finished. Score: (31.37651821862348, 42.91497975708502, 50.202429149797574). Weights: [0.44832434 0.15857093 0.39310473]\n",
            "Remaining time: 2714.870563333854 \n",
            "\n",
            "\n",
            "6/1000 iteration finished. Score: (31.37651821862348, 43.927125506072876, 49.59514170040486). Weights: [0.70357803 0.19490231 0.10151966]\n",
            "Remaining time: 2756.454582509439 \n",
            "\n",
            "\n",
            "7/1000 iteration finished. Score: (31.57894736842105, 43.11740890688259, 50.0). Weights: [0.0538417  0.43975671 0.50640159]\n",
            "Remaining time: 2744.8515880899504 \n",
            "\n",
            "\n",
            "8/1000 iteration finished. Score: (32.18623481781376, 44.534412955465584, 51.417004048582996). Weights: [0.11104873 0.62469805 0.26425323]\n",
            "###############Found###############\n",
            "Old Score: (31.983805668016196, 45.54655870445344, 51.61943319838057), New Score: (32.18623481781376, 44.534412955465584, 51.417004048582996), Old Weights: [0.01729121 0.84797527 0.13473352], New Weights: [0.11104873 0.62469805 0.26425323]\n",
            "Remaining time: 2692.5705917521263 \n",
            "\n",
            "\n",
            "9/1000 iteration finished. Score: (31.37651821862348, 42.91497975708502, 49.797570850202426). Weights: [0.51048235 0.08626158 0.40325607]\n",
            "Remaining time: 2703.3197706897045 \n",
            "\n",
            "\n",
            "10/1000 iteration finished. Score: (31.37651821862348, 43.31983805668016, 50.0). Weights: [0.33899752 0.30228282 0.35871966]\n",
            "Remaining time: 2737.157806363044 \n",
            "\n",
            "\n",
            "11/1000 iteration finished. Score: (31.781376518218625, 44.33198380566802, 50.80971659919028). Weights: [0.23625284 0.47126467 0.29248249]\n",
            "Remaining time: 2701.0033433820354 \n",
            "\n",
            "\n",
            "12/1000 iteration finished. Score: (31.781376518218625, 42.30769230769231, 48.987854251012145). Weights: [0.54443977 0.00740907 0.44815116]\n",
            "Remaining time: 2694.897989677236 \n",
            "\n",
            "\n",
            "13/1000 iteration finished. Score: (31.37651821862348, 43.927125506072876, 50.202429149797574). Weights: [0.59609878 0.12506195 0.27883927]\n",
            "Remaining time: 2673.7413143685553 \n",
            "\n",
            "\n",
            "14/1000 iteration finished. Score: (30.364372469635626, 40.48582995951417, 49.19028340080972). Weights: [0.31354346 0.06867187 0.61778468]\n",
            "Remaining time: 2676.1539071927837 \n",
            "\n",
            "\n",
            "15/1000 iteration finished. Score: (31.57894736842105, 44.12955465587044, 50.607287449392715). Weights: [0.15480079 0.50178214 0.34341707]\n",
            "Remaining time: 2678.6590050081722 \n",
            "\n",
            "\n",
            "16/1000 iteration finished. Score: (31.57894736842105, 44.12955465587044, 50.607287449392715). Weights: [0.39932973 0.34799556 0.25267471]\n",
            "Remaining time: 2897.77136983283 \n",
            "\n",
            "\n",
            "17/1000 iteration finished. Score: (31.57894736842105, 44.73684210526316, 51.21457489878542). Weights: [0.02853705 0.87431381 0.09714915]\n",
            "Remaining time: 3157.4384000450373 \n",
            "\n",
            "\n",
            "18/1000 iteration finished. Score: (29.554655870445345, 41.902834008097166, 48.987854251012145). Weights: [0.06036547 0.28312204 0.65651249]\n",
            "Remaining time: 2828.504019241518 \n",
            "\n",
            "\n",
            "19/1000 iteration finished. Score: (31.57894736842105, 43.7246963562753, 50.202429149797574). Weights: [0.50248254 0.21102251 0.28649495]\n",
            "Remaining time: 2840.385165802436 \n",
            "\n",
            "\n",
            "20/1000 iteration finished. Score: (31.983805668016196, 44.534412955465584, 51.012145748987855). Weights: [0.23016416 0.50174618 0.26808967]\n",
            "Remaining time: 2860.2831506762304 \n",
            "\n",
            "\n",
            "21/1000 iteration finished. Score: (31.37651821862348, 44.12955465587044, 49.59514170040486). Weights: [0.65948144 0.24093413 0.09958444]\n",
            "Remaining time: 2735.0463206580025 \n",
            "\n",
            "\n",
            "22/1000 iteration finished. Score: (31.37651821862348, 42.71255060728745, 49.19028340080972). Weights: [0.21572449 0.23418518 0.55009032]\n",
            "Remaining time: 2697.7445170992287 \n",
            "\n",
            "\n",
            "23/1000 iteration finished. Score: (31.37651821862348, 42.71255060728745, 48.78542510121458). Weights: [0.37872157 0.09327995 0.52799849]\n",
            "Remaining time: 2692.8394026439637 \n",
            "\n",
            "\n",
            "24/1000 iteration finished. Score: (31.37651821862348, 44.12955465587044, 49.59514170040486). Weights: [0.66499611 0.23967969 0.09532419]\n",
            "Remaining time: 2722.2493486711755 \n",
            "\n",
            "\n",
            "25/1000 iteration finished. Score: (30.97165991902834, 42.10526315789474, 49.59514170040486). Weights: [0.10858468 0.30077693 0.59063839]\n",
            "Remaining time: 2687.981177040958 \n",
            "\n",
            "\n",
            "26/1000 iteration finished. Score: (31.57894736842105, 42.91497975708502, 49.19028340080972). Weights: [0.43997208 0.13053318 0.42949473]\n",
            "Remaining time: 2665.981074172567 \n",
            "\n",
            "\n",
            "27/1000 iteration finished. Score: (31.781376518218625, 44.93927125506073, 51.012145748987855). Weights: [0.25232959 0.62254304 0.12512737]\n",
            "Remaining time: 2640.988071331638 \n",
            "\n",
            "\n",
            "28/1000 iteration finished. Score: (31.57894736842105, 44.534412955465584, 50.202429149797574). Weights: [0.56519332 0.30090821 0.13389847]\n",
            "Remaining time: 2661.548658281099 \n",
            "\n",
            "\n",
            "29/1000 iteration finished. Score: (31.781376518218625, 43.7246963562753, 50.80971659919028). Weights: [0.29768346 0.36930705 0.33300949]\n",
            "Remaining time: 2654.6253888390493 \n",
            "\n",
            "\n",
            "30/1000 iteration finished. Score: (31.37651821862348, 42.30769230769231, 48.38056680161943). Weights: [0.47987799 0.00166048 0.51846153]\n",
            "Remaining time: 2636.377516216744 \n",
            "\n",
            "\n",
            "31/1000 iteration finished. Score: (31.983805668016196, 45.54655870445344, 51.21457489878542). Weights: [0.26522138 0.54392619 0.19085242]\n",
            "Remaining time: 2631.322264982853 \n",
            "\n",
            "\n",
            "32/1000 iteration finished. Score: (31.57894736842105, 43.522267206477736, 50.40485829959514). Weights: [0.38283436 0.29961289 0.31755275]\n",
            "Remaining time: 2879.6696306499944 \n",
            "\n",
            "\n",
            "33/1000 iteration finished. Score: (31.17408906882591, 43.11740890688259, 50.0). Weights: [0.33458475 0.29159131 0.37382394]\n",
            "Remaining time: 2756.8094863567385 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-6c6d1e00ef75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuncs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtop1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_run_combined2_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatin_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_latin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msingle_max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mover_max\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-f33e5c8af4a6>\u001b[0m in \u001b[0;36mclassification_run_combined2_general\u001b[0;34m(train_set, test_set, ftype, _costs, _costs2, weights, verbose, func)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                         \u001b[0mcosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgeneral_standard_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-4bad2805f721>\u001b[0m in \u001b[0;36mgeneral_standard_distance\u001b[0;34m(img1, img2, func)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0muv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0muu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0mvv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d8lTcL97Sfv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Runs:"
      ]
    },
    {
      "metadata": {
        "id": "aERN-ZQRdX6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pcorrect, costs_euclidean_modified, costs_cosine_std = classification_run_combined2(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3iaygPGcOHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.argmin(costs_euclidean_modified[3],axis=1))\n",
        "print(\"\\n \\n \\n\")\n",
        "print(costs_euclidean_modified[3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyxwoRST2kfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.uniform(0,3,3)\n",
        "    x = classification_run_combined(latin_samples,new_latin, weights = w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6J4kI2ZsXMMT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    start = timeit.default_timer()\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.standard_t(10,3)\n",
        "    x , _ , _ = classification_run_combined2(latin_samples,new_latin, weights=w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i, \". weights: \",w, \" score:\",x)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    print(\"{0}/100 finished. Remaining time {1}\".format(i, (100-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJc9aQMWQPMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5RKn3ZIQOgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_run(latin_samples, new_latin, manhattan_distance_modified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JC-hpKubaRAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x , y, z = classification_run_combined2(latin_samples, new_latin, _costs = costs_euclidean_modified, _costs2 = costs_cosine_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTDp11EHj1G5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classification_run_combined(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsj4EjROUvdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[general_standard_distance, general_standard_distance, general_standard_distance], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9U_99GEUtsY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### does t-SNE work?\n",
        "\n",
        "It predicts  same class for  every test instances.  FIX"
      ]
    },
    {
      "metadata": {
        "id": "c-cKDR9RUsyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def classification_run_tsne(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    \n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    _tsne = TSNE(n_components=2)\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    test_tsne, train_tsne = _tsne.fit_transform(test_set[i,k]), _tsne.fit_transform(train_set[c])\n",
        "                    costs[i,k,c]  = func[0](test_tsne, train_tsne)\n",
        "                    costs2[i,k,c] = func[1](test_tsne, train_tsne)\n",
        "                    costs3[i,k,c] = func[2](test_tsne, train_tsne)\n",
        "                    \n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "    plt.show()\n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlFQKZVHWBbi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "asd = new_latin[0:2]\n",
        "x ,y ,z = classification_run_tsne(latin_samples, asd,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}