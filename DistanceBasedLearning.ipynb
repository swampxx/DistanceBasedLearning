{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistanceBasedLearning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Ee_PILA4IJWN",
        "peA9CqHzIgyR",
        "P2YL-GHSV2zL",
        "ZBGpCUBudPfM",
        "qAm6NfqFamzz",
        "eQCEm94jHrNg",
        "K6DF2HCgzNoO",
        "YkH--BQHNsON",
        "R9U_99GEUtsY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swampxx/DistanceBasedLearning/blob/master/DistanceBasedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ee_PILA4IJWN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "id": "lFcQMRGKIR7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!rm -r CMANN\n",
        "#!git clone https://github.com/Orkun-tanik/CMANN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "peA9CqHzIgyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Omniglot"
      ]
    },
    {
      "metadata": {
        "id": "48OyelLWJQYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The Omniglot* dataset is a collection of 1623 hand drawn characters from 50 alphabets. For every character there are just 20 examples, each drawn by a different person at resolution 105x105."
      ]
    },
    {
      "metadata": {
        "id": "rJjxbj1QJT4_",
        "colab_type": "code",
        "outputId": "493dc649-a0de-4d6c-b695-a74a4cceb900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "#!unzip CMANN/images_evaluation.zip\n",
        "#!unzip CMANN/images_background.zip\n",
        "\n",
        "\"\"\"  Do not execute again!!  \"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Do not execute again!!  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "K1GOfegpNEtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyQ4fqrQdBVB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_origin(image):\n",
        "    \"\"\"\n",
        "       Image: Black pixels labeled as True\n",
        "        \n",
        "       It moves the image towards the origin,\n",
        "                returns new_image and black pixels coordinates array: (new_image,blacks)  \n",
        "                \n",
        "    \"\"\"\n",
        "\n",
        "    x,y = image.shape\n",
        "    xshift = x\n",
        "    yshift = y\n",
        "\n",
        "    blacks = []\n",
        "\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j))\n",
        "                if i<xshift:\n",
        "                    xshift = i\n",
        "                if j<yshift:\n",
        "                    yshift = j\n",
        "\n",
        "    new_image = np.zeros(shape=(x,y))\n",
        "\n",
        "    for i in range(len(blacks)):\n",
        "        (a,b) = blacks[i]\n",
        "        blacks[i] = (a-xshift, b-yshift)\n",
        "        new_image[a-xshift][b-yshift] = 1\n",
        "    \n",
        "    blacks = np.array(blacks)\n",
        "\n",
        "    return (new_image, blacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Mli7B2nJljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = \"\"\n",
        "train_path = os.path.join(data_path,'images_background')\n",
        "validation_path = os.path.join(data_path,'images_evaluation')\n",
        "\n",
        "\n",
        "\n",
        "def load_images_from_directory(path):\n",
        "    X=[]\n",
        "\n",
        "    ## We load every alphabet seperately and append that to one tensor\n",
        "    for alphabet in os.listdir(path):\n",
        "        #print(\"loading alphabet: \" + alphabet)\n",
        "        alphabet_path = os.path.join(path,alphabet)\n",
        "        \n",
        "        ## Each character in alphabet is in a separate folder\n",
        "        for letter in os.listdir(alphabet_path):\n",
        "            #print(\" + letter: \" + letter)\n",
        "            category_images=[]\n",
        "            letter_path = os.path.join(alphabet_path, letter)\n",
        "        \n",
        "            \n",
        "            if not os.path.isdir(letter_path):\n",
        "                continue\n",
        "\n",
        "            ## Read every image in this directory\n",
        "            for filename in os.listdir(letter_path):\n",
        "                image_path = os.path.join(letter_path, filename)\n",
        "                image = mpimg.imread(image_path)\n",
        "                #print(image)\n",
        "                \n",
        "                \n",
        "                #TODO: recreate images with black pixels coordinate values\n",
        "                \n",
        "                \n",
        "                ### Image preprocessing!\n",
        "                #image = image/255\n",
        "                #image = 1-image\n",
        "                \n",
        "                image = np.logical_not(image)\n",
        "                #print(\"prepocessing image...\")\n",
        "                \n",
        "                new_image, _ = to_origin(image)\n",
        "                \n",
        "                \n",
        "                #print(\"done.\")\n",
        "                #print(image)           \n",
        "                \n",
        "                category_images.append(new_image)\n",
        "            \n",
        "            try:\n",
        "                X.append(np.array(category_images))\n",
        "            #edge case  - last one\n",
        "            except ValueError as e:\n",
        "                print(e)\n",
        "                print(\"error - category_images:\", category_images)\n",
        "    \n",
        "    X = np.array(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gwvm2R90PCFK",
        "colab_type": "code",
        "outputId": "df1773a6-c5bc-49dd-d5be-326cc5b6416b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Loading training set\")\n",
        "#Xtrain = load_images_from_directory(train_path)\n",
        "#print(Xtrain.shape)\n",
        "\n",
        "print(\"Now loading evaluation set\")\n",
        "#Xval = load_images_from_directory(validation_path)\n",
        "#print(Xval.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training set\n",
            "Now loading evaluation set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jHsxmnlPNgm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#np.save('Xtrain.npy', Xtrain)\n",
        "#np.save('Xval.npy', Xval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEaVm3uTuTpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Xtrain = np.load(\"Xtrain.npy\")\n",
        "#Xval = np.load(\"Xval.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Lzrn79ENmN_",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "abc622a0-921f-48ca-9257-9b02c6df181b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"#@title Example Image to be displayed { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 270 #@param {type:\"integer\"}\n",
        "drawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "\n",
        "if (image_set == 'Xval'):\n",
        "    imgplot = plt.imshow(Xval[character,drawing])\n",
        "else:\n",
        "    imgplot = plt.imshow(Xtrain[character,drawing])\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#@title Example Image to be displayed { run: \"auto\" }\\nimport matplotlib.pyplot as plt\\n\\ncharacter = 270 #@param {type:\"integer\"}\\ndrawing = 16 #@param {type:\"slider\", min:0, max:19, step:1}\\nimage_set = \\'Xtrain\\' #@param [\"Xval\", \"Xtrain\"]\\n\\nif (image_set == \\'Xval\\'):\\n    imgplot = plt.imshow(Xval[character,drawing])\\nelse:\\n    imgplot = plt.imshow(Xtrain[character,drawing])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "P2YL-GHSV2zL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Latin Images"
      ]
    },
    {
      "metadata": {
        "id": "Ct5DyzmNWjc3",
        "colab_type": "code",
        "outputId": "9d5815ca-4328-4619-f5eb-9a5604d5dc79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "latin_path = \"Latin\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "latin = load_images_from_directory(latin_path)\n",
        "print(latin.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(26, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8lU37kuPT_j",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "cf17ec5b-fea1-4eb0-9291-534d0a2f2883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin[character,drawing])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63a9ec4d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "eiOL3XzPQE6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def black_pixels(image):\n",
        "    \"\"\"\n",
        "       returns black pixel coordinates of image, array-like\n",
        "    \"\"\"\n",
        "    \n",
        "    x,y = image.shape\n",
        "    blacks = []\n",
        "    for i in range(x):\n",
        "        for j in range(y):\n",
        "            if image[i][j] == True:\n",
        "                blacks.append((i,j)) \n",
        "\n",
        "\n",
        "\n",
        "    return np.array(blacks)\n",
        "\n",
        "# Extract random samples from each character of given alphabet\n",
        "\n",
        "def get_sample(alphabet):\n",
        "    \n",
        "    \"\"\"\n",
        "        alphabet numpy array [size, drawing, 105, 105]\n",
        "    \n",
        "        returns samples and altered alphabet\n",
        "    \"\"\"\n",
        "    character_count, drawing_count, _, _ = alphabet.shape\n",
        "    samples = []\n",
        "    new_alphabet = []    \n",
        "    for i in range(character_count):\n",
        "        rand = np.random.randint(0,drawing_count)\n",
        "        samples.append(alphabet[i,rand])\n",
        "        new_alphabet.append(np.delete(alphabet[i], rand, 0))  \n",
        "    \n",
        "    \n",
        "    samples = np.array(samples)\n",
        "    new_alphabet = np.array(new_alphabet)\n",
        "    \n",
        "    return samples, new_alphabet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmQanN0cR1L6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "latin_samples, new_latin = get_sample(latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEtqxXxMU9LV",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "572fd2e1-2bcb-4549-edf8-1fb23e271096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Latin Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 3 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(latin_samples[character])"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f639669b2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IIxwKGRMWK3f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***These sample latin images will be used for testing distance functions. ***"
      ]
    },
    {
      "metadata": {
        "id": "ZBGpCUBudPfM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Greek Images\n"
      ]
    },
    {
      "metadata": {
        "id": "zbwc4pR9dasc",
        "colab_type": "code",
        "outputId": "30cf0abe-fce9-4148-cc4b-51932a5f4e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "greek_path = \"Greek\"\n",
        "#latin_path_evaluation = \"images_evaluation\"\n",
        "\n",
        "print(\"Loading Latin alphabet..\")\n",
        "greek = load_images_from_directory(greek_path)\n",
        "print(greek.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Latin alphabet..\n",
            "(24, 20, 105, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8FBQWGFEdyf5",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "419e22ee-7c2e-43d7-ce2d-c721f1a7ec9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 0 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing = 0 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek[character,drawing])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63a9bb0198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADZFJREFUeJzt3X2onvV9x/H3Z0lMpsVqbBFNZGboWqTMBw5WcYyiLTpXqn+I6MoWSiD/uNU+QKvbH7L/KpRaB0UWtG02xNqlMkVKg6aWsT+WGmvwKT5kOjU+l6ktLbhIv/vjvrKdXzyHk9zX/XSS9wsO576u+7rv63t+yflc3+vhvk6qCkk64PemXYCk2WIoSGoYCpIahoKkhqEgqWEoSGoYCpIaYwmFJJcleSbJ3iQ3jGMdksYjo754KckK4FngM8A+4GHg2qp6aqQrkjQWK8fwnucDe6vqeYAkPwCuABYNhWOyutZw3BhK6e+P/vi30y7hsDz72LHTLkEz6te8/cuq+uhSy40jFNYBL8+b3gd88uCFkmwGNgOs4Vg+mUvGUEp/27fvnnYJh+XSU8+ZdgmaUQ/WthcPZblxhMIhqaotwBaA47N26h/A2P7q8vrlX8yBn8Nw0LDGcaDxFeC0edPru3mSloFxdAoPA2cm2cAgDK4B/mIM6xmJI6VDONjBP5edgw7VyEOhqt5P8tfAdmAF8N2qenLU65E0HiM/JTmMubPX1M+3n7b0gp1RbPWO1A5hKXYMR68Ha9sjVTW31HJe0SipMbWzD33M38of7pbvaO0QDvDshJZipyCpsSw7hWGMskOYpa3ssD+XHYMWY6cgqbHsO4Vxb/FmfUt6oL6j/ViJRsdOQVLDUJDUWPa7DweMejdi1ncbDnZwve5OaFh2CpIaM9EpPPvYsc2WbhRbuWHfY7l1CH31uRBMRyY7BUmNmfhA1PFZWwvdeWka+8VH2tZymDE80sZAA34gStJQZuKYwmImeWGOW0dpwE5BUmOmO4VJONI7BC+D1uGyU5DUWBadwji2dkd6h9CHH6s+utkpSGosi05hlI7WrZ/HFnSo7BQkNY6aTuFo7RCkw2WnIKlxxHcKdgjS4bFTkNQwFCQ1DAVJDUNBUsNQkNQ4Ys8+eNZBGo6dgqTG0KGQ5LQkDyV5KsmTSa7v5q9N8kCS57rvJ46uXEnj1qdTeB/4alWdBVwAXJfkLOAGYEdVnQns6KYlLRNDh0JVvVZVv+ge/xrYA6wDrgC2dottBa7sW6SkyRnJMYUkpwPnAjuBk6vqte6p14GTR7EOSZPROxSSfAj4EfClqvrV/Odq8EclFvzDEkk2J9mVZNd+3utbhqQR6RUKSVYxCIQ7q+qebvYbSU7pnj8FeHOh11bVlqqaq6q5VazuU4akEepz9iHAHcCeqvrWvKfuAzZ2jzcC9w5fnqRJ63Px0kXAXwKPJzlwj6+/Bb4B/DDJJuBF4Op+JUqapKFDoar+HcgiT3/wD0NKWha8olFSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSo3coJFmR5NEk93fTG5LsTLI3yd1JjulfpqRJGUWncD2wZ970zcAtVXUG8DawaQTrkDQhvUIhyXrgz4Hbu+kAFwPbukW2Alf2WYekyerbKXwb+Brwu276JOCdqnq/m94HrFvohUk2J9mVZNd+3utZhqRRGToUknwWeLOqHhnm9VW1parmqmpuFauHLUPSiK3s8dqLgM8luRxYAxwP3AqckGRl1y2sB17pX6akSRm6U6iqG6tqfVWdDlwD/LSqPg88BFzVLbYRuLd3lZImZhzXKXwd+EqSvQyOMdwxhnVIGpM+uw//p6p+Bvyse/w8cP4o3lfS5HlFo6SGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpYShIahgKkhqGgqSGoSCpccSGwvZXd7P91d3TLkNado7YUJA0HENBUsNQkNQwFCQ1DAVJjWUVCpeeeg6XnnrOtMuQjmjLKhQkjZ+hIKlhKEhqGAqSGoaCpMZI/mzcpM0/A7HY5xs8SyENx05BUmNZdgrz2RFIo2WnIKlhKEhqGAqSGr1CIckJSbYleTrJniQXJlmb5IEkz3XfTxxVsZLGr2+ncCvwk6r6OHA2sAe4AdhRVWcCO7ppScvE0KGQ5MPAnwJ3AFTV/1TVO8AVwNZusa3AlX2LlDQ5fTqFDcBbwPeSPJrk9iTHASdX1WvdMq8DJ/ctUtLk9AmFlcB5wG1VdS7wGw7aVaiqAmqhFyfZnGRXkl37ea9HGZJGqU8o7AP2VdXObnobg5B4I8kpAN33Nxd6cVVtqaq5qppbxeoeZUgapaFDoapeB15O8rFu1iXAU8B9wMZu3kbg3l4VSpqovpc5/w1wZ5JjgOeBLzAImh8m2QS8CFzdcx2SJqhXKFTVbmBugacu6fO+kqbHKxolNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVLDUJDUMBQkNQwFSQ1DQVKj7x+D0TJz6annALD91d1LLqOjk52CpIadwlHKbkCLsVOQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDV6hUKSLyd5MskTSe5KsibJhiQ7k+xNcneSY0ZVrKTxGzoUkqwDvgjMVdUngBXANcDNwC1VdQbwNrBpFIVKmoy+uw8rgd9PshI4FngNuBjY1j2/Fbiy5zokTdDQoVBVrwDfBF5iEAbvAo8A71TV+91i+4B1fYuUNDl9dh9OBK4ANgCnAscBlx3G6zcn2ZVk137eG7YMSSPWZ/fh08ALVfVWVe0H7gEuAk7odicA1gOvLPTiqtpSVXNVNbeK1T3KkDRKfULhJeCCJMcmCXAJ8BTwEHBVt8xG4N5+JUqapD7HFHYyOKD4C+Dx7r22AF8HvpJkL3AScMcI6pQ0Ib0+Ol1VNwE3HTT7eeD8Pu8raXq8olFSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSw1CQ1DAUJDUMBUkNQ0FSY8lQSPLdJG8meWLevLVJHkjyXPf9xG5+kvxDkr1JHkty3jiLlzR6h9IpfB+47KB5NwA7qupMYEc3DfBnwJnd12bgttGUKWlSlgyFqvo34L8Pmn0FsLV7vBW4ct78f6qB/wBOSHLKqIqVNH7DHlM4uape6x6/DpzcPV4HvDxvuX3dvA9IsjnJriS79vPekGVIGrXeBxqrqoAa4nVbqmququZWsbpvGZJGZNhQeOPAbkH3/c1u/ivAafOWW9/Nk7RMDBsK9wEbu8cbgXvnzf+r7izEBcC783YzJC0DK5daIMldwKeAjyTZB9wEfAP4YZJNwIvA1d3iPwYuB/YCvwW+MIaaJY3RkqFQVdcu8tQlCyxbwHV9i5I0PV7RKKlhKEhqGAqSGoaCpEYGxwanXETyFvAb4JfTruUQfITZr9MaR2c51HmoNf5BVX10qYVmIhQAkuyqqrlp17GU5VCnNY7Ocqhz1DW6+yCpYShIasxSKGyZdgGHaDnUaY2jsxzqHGmNM3NMQdJsmKVOQdIMmIlQSHJZkme6ezvesPQrxi/JaUkeSvJUkieTXN/NX/D+lFOudUWSR5Pc301vSLKzG8+7kxwzAzWekGRbkqeT7Ely4ayNZZIvd//WTyS5K8maWRjLSd8ndeqhkGQF8B0G93c8C7g2yVnTrQqA94GvVtVZwAXAdV1di92fcpquB/bMm74ZuKWqzgDeBjZNparWrcBPqurjwNkM6p2ZsUyyDvgiMFdVnwBWANcwG2P5fSZ5n9SqmuoXcCGwfd70jcCN065rgTrvBT4DPAOc0s07BXhmynWt7/5TXAzcD4TBhSwrFxrfKdX4YeAFumNY8+bPzFjy/7cSXMvg08P3A5fOylgCpwNPLDV2wD8C1y603KF+Tb1T4DDu6zgtSU4HzgV2svj9Kafl28DXgN910ycB71TV+930LIznBuAt4Hvdbs7tSY5jhsayql4Bvgm8BLwGvAs8wuyN5QG975O6mFkIhZmW5EPAj4AvVdWv5j9Xgyie2umbJJ8F3qyqR6ZVwyFaCZwH3FZV5zK4pL3ZVZiBsTyRwd3INwCnAsfxwZZ9Jo167GYhFGb2vo5JVjEIhDur6p5u9mL3p5yGi4DPJfkv4AcMdiFuZXBr/QM30JmF8dwH7Kuqnd30NgYhMUtj+Wnghap6q6r2A/cwGN9ZG8sDxnaf1FkIhYeBM7ujvMcwOLhz35RrIkmAO4A9VfWteU8tdn/KiauqG6tqfVWdzmDcflpVnwceAq7qFptqjQBV9TrwcpKPdbMuAZ5ihsaSwW7DBUmO7f7tD9Q4U2M5z/jukzqtAzsHHUS5HHgW+E/g76ZdT1fTnzBoyR4DdndflzPYZ98BPAc8CKyddq1dvZ8C7u8e/yHwcwb3yvwXYPUM1HcOsKsbz38FTpy1sQT+HngaeAL4Z2D1LIwlcBeD4xz7GXRdmxYbOwYHmr/T/S49zuBsymGtzysaJTVmYfdB0gwxFCQ1DAVJDUNBUsNQkNQwFCQ1DAVJDUNBUuN/AcmCg/fMVBpAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_wl7kyGMd6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract samples from latin alphabet\n",
        "greek_samples, new_greek = get_sample(greek)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sVN57oPWd_KJ",
        "colab_type": "code",
        "outputId": "e50e9a8a-efd4-441c-88a2-55e39f6e2b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Sample Greek Images { run: \"auto\" }\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "character = 16 #@param {type:\"slider\", min:0, max:23, step:1}\n",
        "#image_set = 'Xtrain' #@param [\"Xval\", \"Xtrain\"]\n",
        "plt.imshow(greek_samples[character])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f63a990c048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3u3QOMrMWgkJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*In this section,  there are experiments of distance functions for one-shot learning . Follow the headers for distance functions properties.*\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ftfT02r3X1Sw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Elementary Distance Functions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "* Minkowski Family\n",
        "> *   Euclidean \n",
        "> *   Manhattan\n",
        "> *  LP Norm Distance Function\n",
        "\n",
        "* Angular Distance Functions\n",
        ">* Cosine Similarity"
      ]
    },
    {
      "metadata": {
        "id": "qAm6NfqFamzz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ">### Euclidean\n",
        "---\n",
        "Euclidean distance is a special case of Minkowski distance with $\\lambda=2$\n",
        "\n",
        "$Euclidean(\\vec{x}, \\vec{y}):= \\sqrt{\\sum_i(x_i-y_i)^2}$\n"
      ]
    },
    {
      "metadata": {
        "id": "_h3gndV8_LcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.spatial.distance as distance\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "def mins_helper(arr):\n",
        "    \n",
        "    indexed_used = []\n",
        "    for i in range(len(arr)):\n",
        "\n",
        "        row_min = np.argmin(arr[i])\n",
        "        if row_min in indexed_used:\n",
        "            new_row = arr[i]\n",
        "            new_row[row_min] = 999\n",
        "            row_min = np.argmin(new_row)     \n",
        "        \n",
        "        indexed_used.append(row_min)\n",
        "    \n",
        "    return indexed_used\n",
        "\n",
        "def euclidean_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: x and y images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.euclidean(v1, v2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "def euclidean_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v1.shape )\n",
        "    \n",
        "    #print(\"black pixel count of img1: \", v2.shape )\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    difference_sum = np.mean(np.amin(dist,axis=1))\n",
        "    \n",
        "    return difference_sum\n",
        "\n",
        "def euclidean_distance_modified_v2(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        It extracts each black pixels from images, find their coordinates on\n",
        "        x-y plane by taking origin as a reference.\n",
        "        \n",
        "        Then, computes distance between all pixel pairs and sums minimum\n",
        "        distance along axis=1 (row based).\n",
        "        \n",
        "        can be normalized, divides with biggest distance on the plane\n",
        "        diagonal sqrt(max_x**2+max_y**2)\n",
        "        \n",
        "        returns: modified euclidean distance\n",
        "        \n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'euclidean')\n",
        "    \n",
        "    d = mins_helper(dist)\n",
        "    sum = 0\n",
        "    for i in range(len(dist)):\n",
        "        sum += dist[i,d[i]]\n",
        "    return sum/len(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQCEm94jHrNg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Manhattan\n",
        "---\n",
        "Manhattan distance is a special case of Minkowski distance with $\\lambda=1$\n",
        "\n",
        "$Manhattan(\\vec{x}, \\vec{y}):= \\sqrt{\\sum\\limits_i |x_i-y_i|}$\n",
        "\n",
        "Since flatten function is used, standard manhattan distance can be deceptive.\n",
        "\n",
        "A modified Manhattan distance will be more informative}."
      ]
    },
    {
      "metadata": {
        "id": "IO1gM_mIIikv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def manhattan_distance_std(img1,img2):\n",
        "    \"\"\"\n",
        "        params: img1 and img2 images\n",
        "        \n",
        "        To apply eucl. distance It transforms images to 1D vectors by flatten()\n",
        "        \n",
        "        return: euclidean distance between two images\n",
        "       \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cityblock(v1, v2)\n",
        "\n",
        "def manhattan_distance_modified(img1,img2):\n",
        "    \"\"\"\n",
        "        params: images\n",
        "        \n",
        "        Like modified euclidean, finds coordinates of black pixels, then\n",
        "        computes distance.\n",
        "        \n",
        "        \n",
        "        return manhattan distance between two images\n",
        "    \"\"\"\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'cityblock')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K6DF2HCgzNoO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity\n",
        "\n",
        "$CosineSimilarity(\\vec{x} , \\vec{y}) =\\dfrac{\\vec{x}.\\vec{y}}{||a||.||b||} $\n"
      ]
    },
    {
      "metadata": {
        "id": "oRr5_Pwm3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_distance_std(img1, img2):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.cosine(v1, v2)\n",
        "\n",
        "\n",
        "def arccos_distance(img1,img2):\n",
        "    \n",
        "    cos_sim = 1 - cosine_distance_std(img1,img2)\n",
        "    \n",
        "    return (math.acos(cos_sim))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkH--BQHNsON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dynamic Time Warping"
      ]
    },
    {
      "metadata": {
        "id": "H8thSBeT3kZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dynamic Time Warping implementation\n",
        "from fastdtw import fastdtw\n",
        "\n",
        "def dtw(img1,img2):\n",
        "    dist,path = fastdtw(img1,img2,dist = distance.jaccard)\n",
        "    \n",
        "    return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fV7cYZNuNuoS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Canberra Distance"
      ]
    },
    {
      "metadata": {
        "id": "zjie1_iEDKNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def canberra_distance_std(img1, img2):\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.canberra(v1, v2)\n",
        "\n",
        "def canberra_distance_modified(img1, img2):\n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    \n",
        "    dist = distance.cdist(v1,v2,'canberra')\n",
        "    \n",
        "    difference_sum = np.sum(np.amin(dist,axis=1))/len(dist)\n",
        "    \n",
        "    return difference_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZRBTXP-RJJM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Other Standard Distance Functions"
      ]
    },
    {
      "metadata": {
        "id": "dbI2jCUbcLUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def braycurtis_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.braycurtis(v1, v2)\n",
        "\n",
        "def chebyshev_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.chebyshev(v1, v2)\n",
        "\n",
        "\n",
        "def correlation_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.correlation(v1, v2)\n",
        "\n",
        "def jensenshannon_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.jensenshannon(v1, v2)\n",
        "\n",
        "def hamming_distance_std(img1,img2):\n",
        "\n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return distance.hamming(v1, v2)\n",
        "\n",
        "\n",
        "\n",
        "def general_standard_distance(img1,img2, func):\n",
        "    \n",
        "    v1 = img1.flatten()\n",
        "    v2 = img2.flatten()\n",
        "    \n",
        "    return func(v1,v2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4JTQJFthHTAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def distance_wrt_origin(img1,img2,distance_function):\n",
        "    \"\"\"\n",
        "      Calculates distance with respect to origin based on distance_function\n",
        "      \n",
        "      Extracts black pixels and calculate its coordinates, then sum distance to origin\n",
        "      \n",
        "      return both of the distances in a tuple like (v1_sum, v2_sum)\n",
        "      \n",
        "    \"\"\"\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    max_x, max_y = img1.shape\n",
        "    \n",
        "    v1 = black_pixels(img1)\n",
        "    v2 = black_pixels(img2)\n",
        "    \n",
        "    # Number of black pixels is not same for every image pair.\n",
        "    \n",
        "    # Randomly select black pixels from larger one\n",
        "    randoms = np.random.permutation(min(len(v1), len(v2)))\n",
        "    \n",
        "    if len(v1) < len(v2) :\n",
        "        v2 = v2[randoms[:]]\n",
        "    else:\n",
        "        v1 = v1[randoms[:]]\n",
        "    \n",
        "    v1_sum = np.sum(distance.cdist(v1,[[0,0]], distance_function))\n",
        "    v2_sum = np.sum(distance.cdist(v2,[[0,0]], distance_function))\n",
        "    \n",
        "    \n",
        "    return v1_sum,v2_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2djM80TDImjo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distance Functions Experiment Suite"
      ]
    },
    {
      "metadata": {
        "id": "UdwdLaLYamkt",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "a1fe99dc-0070-4caa-92b7-3e8ba8479022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "#@title  { run: \"auto\" }\n",
        "#@markdown Select characters and drawings to compute distances.\n",
        "\n",
        "\n",
        "\n",
        "character1 = 11 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing1 = 6 #@param {type:\"slider\", min:0, max:19, step:1}\n",
        "\n",
        "character2 = 16 #@param {type:\"slider\", min:0, max:25, step:1}\n",
        "drawing2 = 7 #@param {type:\"slider\", min:0, max:18, step:1}\n",
        "\n",
        "img1 = new_latin[character1,drawing1]\n",
        "img2 = new_latin[character2,drawing2]\n",
        "\n",
        "#print(latin.shape)\n",
        "\n",
        "fig=plt.figure(figsize=(8, 8))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "imgplot = plt.imshow(img1)\n",
        "fig.add_subplot(1, 2, 2)\n",
        "imgplot = plt.imshow(img2)\n",
        "\n",
        "\n",
        "print(\"standard euclidean distance: \", euclidean_distance_std(img1,img2))\n",
        "print(\"modified euclidean distance: \", euclidean_distance_modified(img1,img2))\n",
        "print(\"modified euclidean distance_v2: \", euclidean_distance_modified_v2(img1,img2))\n",
        "print(\"standard manhattan distance: \",manhattan_distance_std(img1,img2))\n",
        "print(\"modified manhattan distance: \", manhattan_distance_modified(img1,img2))\n",
        "print(\"cosine similarity: \",cosine_distance_std(img1,img2))\n",
        "print(\"arccos similarity: \", arccos_distance(img1,img2))\n",
        "print(\"standard canberra distance: \", canberra_distance_std(img1,img2))\n",
        "print(\"modified canberra distance: \", canberra_distance_modified(img1,img2))\n",
        "\n",
        "print(\"dtw trial: \", dtw(img1, img2))\n",
        "\n",
        "v1_sum, v2_sum = distance_wrt_origin(img1,img2,\"euclidean\")\n",
        "print(\"Scores... img1: {0} and img2: {1} \".format(v1_sum,v2_sum))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard euclidean distance:  31.74901573277509\n",
            "modified euclidean distance:  23.276654043334887\n",
            "modified euclidean distance_v2:  23.389387964320274\n",
            "standard manhattan distance:  1008.0\n",
            "modified manhattan distance:  23.63157894736842\n",
            "cosine similarity:  0.8329994404465064\n",
            "arccos similarity:  1.4030096086841084\n",
            "standard canberra distance:  1008.0\n",
            "modified canberra distance:  0.25347404903187304\n",
            "dtw trial:  59.574743364874585\n",
            "Scores... img1: 34207.58285379298 and img2: 18795.865242432075 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lQCykxHdM-Ez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ]
    },
    {
      "metadata": {
        "id": "Tya0Md9-D4JQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clasiffication runs according to basic non-parametric distance functions"
      ]
    },
    {
      "metadata": {
        "id": "TPovucPCSTO5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1 ) For testing some methods. Ignore this section."
      ]
    },
    {
      "metadata": {
        "id": "ECbEKBF8KEtG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def classification_run(train_set, test_set, f_cost, ftype='cost'):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                costs[i,k,c] = f_cost(test_set[i,k],train_set[c])\n",
        "        stop = timeit.default_timer()\n",
        "        \n",
        "        print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    \n",
        "    for i in range(n_test_class):\n",
        "        print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "    \n",
        "    print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                             100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLQF-pm1QSX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_run_combined(train_set, test_set, ftype='cost', weights = [1,1,1], verbose = 1, func=[ euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    \n",
        "    costs_1 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs_3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        start = timeit.default_timer()\n",
        "        for k in range(n_test_instances):\n",
        "            for c in range(n_train):\n",
        "                if ex_arg is None:\n",
        "                    costs_1[i,k,c] = func[0](test_set[i,k],train_set[c])\n",
        "                    costs_2[i,k,c] = func[1](test_set[i,k],train_set[c])\n",
        "                    costs_3[i,k,c] = func[2](test_set[i,k],train_set[c])\n",
        "\n",
        "        stop = timeit.default_timer()\n",
        "        if verbose:\n",
        "            print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        predicted_class2 = []\n",
        "        predicted_class3 = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_1[i],1,axis=1))\n",
        "            predicted_class2.append(np.argpartition(costs_2[i],1,axis=1))\n",
        "            predicted_class3.append(np.argpartition(costs_3[i],1,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    flag=0\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            votes = np.zeros((n_test_class))\n",
        "            votes[predicted_class[i][j][0]]  += weights[0]\n",
        "            votes[predicted_class2[i][j][0]] += weights[1]\n",
        "            votes[predicted_class3[i][j][0]] += weights[2]\n",
        "\n",
        "            if np.argmax(votes) == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "            if flag: \n",
        "                flag -= 1\n",
        "                print(votes)\n",
        "    \n",
        "    if verbose:      \n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}\".format(i,class_scores[i], n_test_instances))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {2}\".format(correct,n_test_class * n_test_instances,100 * correct / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    return pcorrect\n",
        "\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMUk52RVdCpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def classification_run_combined2(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    costs[i,k,c]  = func[0](test_set[i,k],train_set[c])\n",
        "                    costs2[i,k,c] = func[1](test_set[i,k], train_set[c])\n",
        "                    costs3[i,k,c] = func[2](test_set[i,k], train_set[c])\n",
        "\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3vSXR_ESYDW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2) General Classifications with weighted distance sum  and weighted(or not) majority voting"
      ]
    },
    {
      "metadata": {
        "id": "sB8zSJOQlWDU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### with weighted distance sum like $D = w_0d_0 + w_1d_1+...+w_id_i$   $for \\  \\forall \\ d_i \\ is\\ a\\ standard\\ distance\\ function $"
      ]
    },
    {
      "metadata": {
        "id": "xeidI3FDSi6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_general_weighted_distance(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [distance.euclidean, distance.cityblock, distance.cosine]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    n_function = len(func)\n",
        "    \n",
        "    costs  = np.zeros((n_function,n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for f in range(n_function):\n",
        "            start = timeit.default_timer()\n",
        "            for i in range(n_test_class):\n",
        "                for k in range(n_test_instances):\n",
        "                    for c in range(n_train):\n",
        "                        costs[f,i,k,c]  = general_standard_distance(test_set[i,k], train_set[c], func[f])\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test function: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(f+1, stop - start, n_function, (stop-start)*(n_function-f-1)))\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        for f in range(n_function):\n",
        "            for i in range(n_test_class):\n",
        "                for k in range(n_test_instances):\n",
        "                    costs[f,i,k] = costs[f,i,k]/np.max(costs[f,i,k])\n",
        "\n",
        "    costs_res = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    \n",
        "    for f in range(n_function):\n",
        "        costs_res += weights[f] * costs[f] \n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                \"\"\"plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\"\"\"\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXDJPpkyiJtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "funcs = [distance.kulsinski, distance.yule, distance.russellrao, distance.dice]\n",
        "w = [0,0,0,1]\n",
        "x = classification_general_weighted_distance(latin_samples, new_latin, verbose = 1, weights=w, func = funcs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wLjR4g0Supa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "funcs = [distance.kulsinski, distance.yule, distance.russellrao, distance.dice]\n",
        "\n",
        "for i in range(1,100):\n",
        "    start = timeit.default_timer()\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.standard_t(10,len(funcs))\n",
        "    x = classification_general_weighted_distance(latin_samples, new_latin, verbose = 0, weights=w, func = funcs)\n",
        "    print(\"Iteration: {0}, Weights: {1}, Accuracy: {2}\".format(i,w,x))\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i, \". weights: \",w, \" score:\",x)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    print(\"{0}/100 finished. Remaining time {1} \\n\".format(i, (100-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "98MICdScmNzr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### with weighted(or not) majority voting.... NOT FINISHED YET"
      ]
    },
    {
      "metadata": {
        "id": "o9pSS3-HmZm6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classification_general_vote(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [distance.euclidean, distance.cityblock, distance.cosine]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "    n_function = len(func)\n",
        "    \n",
        "    costs  = np.zeros((n_function,n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for f in range(n_function):\n",
        "            start = timeit.default_timer()\n",
        "            for i in range(n_test_class):\n",
        "                for k in range(n_test_instances):\n",
        "                    for c in range(n_train):\n",
        "                        costs[f,i,k,c]  = general_standard_distance(test_set[i,k], train_set[c], func[f])\n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test function: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(f+1, stop - start, n_function, (stop-start)*(n_function-f-1)))\n",
        "\n",
        "        for f in range(n_function):\n",
        "            for i in range(n_test_class):\n",
        "                for k in range(n_test_instances):\n",
        "                    costs[f,i,k] = costs[f,i,k]/np.max(costs[f,i,k])\n",
        "    \n",
        "    \n",
        "    \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "            \n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8lTcL97Sfv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Runs:"
      ]
    },
    {
      "metadata": {
        "id": "aERN-ZQRdX6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pcorrect, costs_euclidean_modified, costs_cosine_std = classification_run_combined2(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3iaygPGcOHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.argmin(costs_euclidean_modified[3],axis=1))\n",
        "print(\"\\n \\n \\n\")\n",
        "print(costs_euclidean_modified[3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyxwoRST2kfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c70f3d3c-d3e0-4257-83d2-6c907c9dc175"
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.uniform(0,3,3)\n",
        "    x = classification_run_combined(latin_samples,new_latin, weights = w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found:  1\n",
            "found:  9\n",
            "Best score found at 9. iteration. Score: 28.74493927125506  Weights: [1.35998181 2.54870804 1.04990091]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6J4kI2ZsXMMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1823
        },
        "outputId": "0dd10949-f628-43c9-8d1f-4f7aad7e839f"
      },
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "best_weights = []\n",
        "turn = 0\n",
        "\n",
        "for i in range(1,100):\n",
        "    start = timeit.default_timer()\n",
        "    if(i%200 == 0): \n",
        "        print(\"200 iteration completed...\")\n",
        "    w = np.random.standard_t(10,3)\n",
        "    x , _ , _ = classification_run_combined2(latin_samples,new_latin, weights=w, verbose = 0, func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std])\n",
        "    if x > best_score:\n",
        "        print(\"found: \", i, \". weights: \",w, \" score:\",x)\n",
        "        best_score = x\n",
        "        best_weights = w\n",
        "        turn = i\n",
        "    end = timeit.default_timer()\n",
        "    print(\"{0}/100 finished. Remaining time {1}\".format(i, (100-i-1)*(end-start)))\n",
        "\n",
        "print(\"Best score found at {0}. iteration. Score: {1}  Weights: {2}\".format(turn,best_score,best_weights))"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/100 finished. Remaining time 702.9189112958265\n",
            "found:  2 . weights:  [ 1.02537583  0.94513437 -0.07683386]  score: 28.74493927125506\n",
            "2/100 finished. Remaining time 706.3537667147029\n",
            "found:  3 . weights:  [ 0.87540825  2.06293917 -0.24589501]  score: 28.94736842105263\n",
            "3/100 finished. Remaining time 680.1124551363755\n",
            "4/100 finished. Remaining time 672.7988789845767\n",
            "5/100 finished. Remaining time 700.2926905597415\n",
            "6/100 finished. Remaining time 660.9356421662669\n",
            "7/100 finished. Remaining time 651.2293738919252\n",
            "8/100 finished. Remaining time 648.6282512715479\n",
            "9/100 finished. Remaining time 642.7143944103591\n",
            "10/100 finished. Remaining time 656.9819664720271\n",
            "11/100 finished. Remaining time 631.7201610716875\n",
            "12/100 finished. Remaining time 619.3831291439856\n",
            "13/100 finished. Remaining time 751.6459917062457\n",
            "14/100 finished. Remaining time 613.4103990502263\n",
            "15/100 finished. Remaining time 634.402594223764\n",
            "16/100 finished. Remaining time 631.631058000843\n",
            "17/100 finished. Remaining time 581.2288245542732\n",
            "18/100 finished. Remaining time 577.411716429262\n",
            "found:  19 . weights:  [-0.14547787  3.40372293 -2.14458437]  score: 30.364372469635626\n",
            "19/100 finished. Remaining time 587.9460618400481\n",
            "20/100 finished. Remaining time 578.0418219520288\n",
            "21/100 finished. Remaining time 556.9073493359465\n",
            "22/100 finished. Remaining time 546.6294964131157\n",
            "23/100 finished. Remaining time 537.7082432639727\n",
            "24/100 finished. Remaining time 531.3979563748944\n",
            "25/100 finished. Remaining time 523.8550804660917\n",
            "26/100 finished. Remaining time 522.5611676069675\n",
            "27/100 finished. Remaining time 520.8117310798843\n",
            "28/100 finished. Remaining time 515.5492330131237\n",
            "29/100 finished. Remaining time 503.2534374699753\n",
            "30/100 finished. Remaining time 546.6387220108736\n",
            "31/100 finished. Remaining time 544.0055128278036\n",
            "32/100 finished. Remaining time 542.8615918059586\n",
            "33/100 finished. Remaining time 491.72865700215334\n",
            "34/100 finished. Remaining time 463.46908802985126\n",
            "35/100 finished. Remaining time 594.7396248956211\n",
            "36/100 finished. Remaining time 456.17979046487744\n",
            "37/100 finished. Remaining time 430.86929828178836\n",
            "38/100 finished. Remaining time 446.966040967287\n",
            "39/100 finished. Remaining time 416.8390407001425\n",
            "40/100 finished. Remaining time 412.00603012694773\n",
            "41/100 finished. Remaining time 422.5268697981519\n",
            "42/100 finished. Remaining time 448.6761262587388\n",
            "43/100 finished. Remaining time 555.8026372079039\n",
            "44/100 finished. Remaining time 433.76235738018295\n",
            "45/100 finished. Remaining time 428.67788976016163\n",
            "46/100 finished. Remaining time 369.8726208346852\n",
            "47/100 finished. Remaining time 362.79358611628413\n",
            "48/100 finished. Remaining time 365.22407986818143\n",
            "49/100 finished. Remaining time 363.4150605001196\n",
            "50/100 finished. Remaining time 383.7998191792285\n",
            "51/100 finished. Remaining time 346.42492296011187\n",
            "52/100 finished. Remaining time 337.97816832611716\n",
            "53/100 finished. Remaining time 330.61709738381614\n",
            "54/100 finished. Remaining time 319.21451032500045\n",
            "55/100 finished. Remaining time 309.8160650639911\n",
            "56/100 finished. Remaining time 305.76598988213664\n",
            "57/100 finished. Remaining time 300.85179696611885\n",
            "found:  58 . weights:  [-0.60148383  1.33530655 -0.61478219]  score: 30.76923076923077\n",
            "58/100 finished. Remaining time 290.34587646294676\n",
            "59/100 finished. Remaining time 283.735578719934\n",
            "60/100 finished. Remaining time 279.28198182298365\n",
            "61/100 finished. Remaining time 292.0869420499657\n",
            "62/100 finished. Remaining time 307.4550795280811\n",
            "63/100 finished. Remaining time 302.0930148960615\n",
            "64/100 finished. Remaining time 288.6873253950762\n",
            "65/100 finished. Remaining time 258.1647422700771\n",
            "66/100 finished. Remaining time 263.4481245661227\n",
            "67/100 finished. Remaining time 250.5524703359697\n",
            "68/100 finished. Remaining time 226.2232582909637\n",
            "69/100 finished. Remaining time 251.55763574992307\n",
            "70/100 finished. Remaining time 230.63551586710673\n",
            "71/100 finished. Remaining time 209.79350254798192\n",
            "72/100 finished. Remaining time 201.61050198300654\n",
            "73/100 finished. Remaining time 194.61276512598852\n",
            "74/100 finished. Remaining time 177.15581110005587\n",
            "75/100 finished. Remaining time 188.7231923280051\n",
            "76/100 finished. Remaining time 178.92344968309044\n",
            "77/100 finished. Remaining time 153.03825325801154\n",
            "78/100 finished. Remaining time 154.26676104000217\n",
            "79/100 finished. Remaining time 155.23233339990838\n",
            "80/100 finished. Remaining time 146.6334343439812\n",
            "81/100 finished. Remaining time 134.07628172409022\n",
            "82/100 finished. Remaining time 135.65609448798205\n",
            "83/100 finished. Remaining time 124.57836267200764\n",
            "84/100 finished. Remaining time 110.58869346008578\n",
            "85/100 finished. Remaining time 100.56364428599773\n",
            "86/100 finished. Remaining time 93.13634413201362\n",
            "87/100 finished. Remaining time 86.48458969205967\n",
            "88/100 finished. Remaining time 78.04978908104385\n",
            "89/100 finished. Remaining time 72.4448480099818\n",
            "90/100 finished. Remaining time 69.96164501697058\n",
            "91/100 finished. Remaining time 60.951120176003315\n",
            "92/100 finished. Remaining time 50.988981035974575\n",
            "93/100 finished. Remaining time 45.5655926700274\n",
            "94/100 finished. Remaining time 40.14292891497462\n",
            "95/100 finished. Remaining time 28.474455519986805\n",
            "96/100 finished. Remaining time 24.28756743598933\n",
            "97/100 finished. Remaining time 14.491616117986268\n",
            "98/100 finished. Remaining time 7.12365198200132\n",
            "99/100 finished. Remaining time 0.0\n",
            "Best score found at 58. iteration. Score: 30.76923076923077  Weights: [-0.60148383  1.33530655 -0.61478219]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJc9aQMWQPMk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "36b2af72-7e2a-4121-cc2b-fa7147adb02c"
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test class: 1/26 completed. Time: 0.6124209749978036 sec. Estimated remaining time: 15.31052437494509 sec\n",
            "Test class: 2/26 completed. Time: 0.350211135999416 sec. Estimated remaining time: 8.405067263985984 sec\n",
            "Test class: 3/26 completed. Time: 0.3778797740014852 sec. Estimated remaining time: 8.69123480203416 sec\n",
            "Test class: 4/26 completed. Time: 0.36567489500157535 sec. Estimated remaining time: 8.044847690034658 sec\n",
            "Test class: 5/26 completed. Time: 0.3251354430030915 sec. Estimated remaining time: 6.827844303064921 sec\n",
            "Test class: 6/26 completed. Time: 0.28801546299655456 sec. Estimated remaining time: 5.760309259931091 sec\n",
            "Test class: 7/26 completed. Time: 0.29098566400352865 sec. Estimated remaining time: 5.528727616067044 sec\n",
            "Test class: 8/26 completed. Time: 0.28706721799972 sec. Estimated remaining time: 5.16720992399496 sec\n",
            "Test class: 9/26 completed. Time: 0.3177019649956492 sec. Estimated remaining time: 5.400933404926036 sec\n",
            "Test class: 10/26 completed. Time: 0.301427626000077 sec. Estimated remaining time: 4.822842016001232 sec\n",
            "Test class: 11/26 completed. Time: 0.3083964699981152 sec. Estimated remaining time: 4.625947049971728 sec\n",
            "Test class: 12/26 completed. Time: 0.27890328699868405 sec. Estimated remaining time: 3.9046460179815767 sec\n",
            "Test class: 13/26 completed. Time: 0.2943996310059447 sec. Estimated remaining time: 3.827195203077281 sec\n",
            "Test class: 14/26 completed. Time: 0.2769646040032967 sec. Estimated remaining time: 3.3235752480395604 sec\n",
            "Test class: 15/26 completed. Time: 0.28416925499914214 sec. Estimated remaining time: 3.1258618049905635 sec\n",
            "Test class: 16/26 completed. Time: 0.2827897099996335 sec. Estimated remaining time: 2.827897099996335 sec\n",
            "Test class: 17/26 completed. Time: 0.27818381800170755 sec. Estimated remaining time: 2.503654362015368 sec\n",
            "Test class: 18/26 completed. Time: 0.2755628750019241 sec. Estimated remaining time: 2.204503000015393 sec\n",
            "Test class: 19/26 completed. Time: 0.27774749800300924 sec. Estimated remaining time: 1.9442324860210647 sec\n",
            "Test class: 20/26 completed. Time: 0.41472424899984617 sec. Estimated remaining time: 2.488345493999077 sec\n",
            "Test class: 21/26 completed. Time: 0.2988630740001099 sec. Estimated remaining time: 1.4943153700005496 sec\n",
            "Test class: 22/26 completed. Time: 0.2877797429973725 sec. Estimated remaining time: 1.15111897198949 sec\n",
            "Test class: 23/26 completed. Time: 0.34378878099960275 sec. Estimated remaining time: 1.0313663429988082 sec\n",
            "Test class: 24/26 completed. Time: 0.2953560290043242 sec. Estimated remaining time: 0.5907120580086485 sec\n",
            "Test class: 25/26 completed. Time: 0.30146275199513184 sec. Estimated remaining time: 0.30146275199513184 sec\n",
            "Test class: 26/26 completed. Time: 0.29777049699623603 sec. Estimated remaining time: 0.0 sec\n",
            " Class 0 : Top1 correct: 3.0/19, Top2 correct: 6.0/19, Top3 correct: 9.0/19\n",
            " Class 1 : Top1 correct: 11.0/19, Top2 correct: 14.0/19, Top3 correct: 14.0/19\n",
            " Class 2 : Top1 correct: 16.0/19, Top2 correct: 19.0/19, Top3 correct: 19.0/19\n",
            " Class 3 : Top1 correct: 6.0/19, Top2 correct: 10.0/19, Top3 correct: 11.0/19\n",
            " Class 4 : Top1 correct: 9.0/19, Top2 correct: 11.0/19, Top3 correct: 12.0/19\n",
            " Class 5 : Top1 correct: 6.0/19, Top2 correct: 12.0/19, Top3 correct: 12.0/19\n",
            " Class 6 : Top1 correct: 1.0/19, Top2 correct: 5.0/19, Top3 correct: 5.0/19\n",
            " Class 7 : Top1 correct: 8.0/19, Top2 correct: 13.0/19, Top3 correct: 13.0/19\n",
            " Class 8 : Top1 correct: 5.0/19, Top2 correct: 7.0/19, Top3 correct: 10.0/19\n",
            " Class 9 : Top1 correct: 2.0/19, Top2 correct: 2.0/19, Top3 correct: 4.0/19\n",
            " Class 10 : Top1 correct: 3.0/19, Top2 correct: 5.0/19, Top3 correct: 14.0/19\n",
            " Class 11 : Top1 correct: 6.0/19, Top2 correct: 9.0/19, Top3 correct: 10.0/19\n",
            " Class 12 : Top1 correct: 7.0/19, Top2 correct: 11.0/19, Top3 correct: 16.0/19\n",
            " Class 13 : Top1 correct: 9.0/19, Top2 correct: 11.0/19, Top3 correct: 13.0/19\n",
            " Class 14 : Top1 correct: 7.0/19, Top2 correct: 12.0/19, Top3 correct: 15.0/19\n",
            " Class 15 : Top1 correct: 9.0/19, Top2 correct: 15.0/19, Top3 correct: 16.0/19\n",
            " Class 16 : Top1 correct: 10.0/19, Top2 correct: 13.0/19, Top3 correct: 14.0/19\n",
            " Class 17 : Top1 correct: 6.0/19, Top2 correct: 8.0/19, Top3 correct: 10.0/19\n",
            " Class 18 : Top1 correct: 1.0/19, Top2 correct: 1.0/19, Top3 correct: 3.0/19\n",
            " Class 19 : Top1 correct: 4.0/19, Top2 correct: 5.0/19, Top3 correct: 7.0/19\n",
            " Class 20 : Top1 correct: 7.0/19, Top2 correct: 8.0/19, Top3 correct: 8.0/19\n",
            " Class 21 : Top1 correct: 2.0/19, Top2 correct: 3.0/19, Top3 correct: 5.0/19\n",
            " Class 22 : Top1 correct: 1.0/19, Top2 correct: 3.0/19, Top3 correct: 5.0/19\n",
            " Class 23 : Top1 correct: 13.0/19, Top2 correct: 13.0/19, Top3 correct: 14.0/19\n",
            " Class 24 : Top1 correct: 5.0/19, Top2 correct: 7.0/19, Top3 correct: 11.0/19\n",
            " Class 25 : Top1 correct: 7.0/19, Top2 correct: 9.0/19, Top3 correct: 12.0/19\n",
            "Total: Top1 -: 164.0/494 = 33.19838056680162, Top2 -: 232.0/494 = 46.963562753036435, Top3 -: 282.0/494 = 57.08502024291498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W5RKn3ZIQOgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_run(latin_samples, new_latin, manhattan_distance_modified))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JC-hpKubaRAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x , y, z = classification_run_combined2(latin_samples, new_latin, _costs = costs_euclidean_modified, _costs2 = costs_cosine_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTDp11EHj1G5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classification_run_combined(latin_samples, new_latin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsj4EjROUvdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x ,y ,z = classification_run_combined2(latin_samples, new_latin,func=[general_standard_distance, general_standard_distance, general_standard_distance], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9U_99GEUtsY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### does t-SNE work?\n",
        "\n",
        "It predicts 0th class every test instances.  FIX"
      ]
    },
    {
      "metadata": {
        "id": "c-cKDR9RUsyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def classification_run_tsne(train_set, test_set, ftype='cost',\n",
        "                                 _costs = None, _costs2 = None, weights = [1,1,1], verbose = 1, func = [euclidean_distance_std, manhattan_distance_std, cosine_distance_std]):\n",
        "    # Compute error rate for one run of one-shot classification\n",
        "    #  n_test : number of unclassified images\n",
        "    #  n_train: number of labeled images\n",
        "    #  f_cost : f_cost(itemA,itemB) should compute similarity between two images, using output of f_load\n",
        "    #  ftype  : 'cost' if small values from f_cost mean more similar, or 'score' if large values are more similar\n",
        "    #\n",
        "    # Output\n",
        "    #  perror : percent errors (0 to 100% error)\n",
        "    # \n",
        "    \n",
        "    \n",
        "    n_train = train_set.shape[0]\n",
        "    n_test_class, n_test_instances = test_set.shape[0:2]\n",
        "\n",
        "    \n",
        "    costs  = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs2 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "    costs3 = np.zeros((n_test_class,n_test_instances,n_train))\n",
        "\n",
        "    _tsne = TSNE(n_components=2)\n",
        "    \n",
        "    if not (_costs is None and _costs2 is None):\n",
        "        costs  = _costs\n",
        "        costs2 = _costs2\n",
        "    else:\n",
        "        for i in range(n_test_class):\n",
        "            start = timeit.default_timer()\n",
        "            for k in range(n_test_instances):\n",
        "                for c in range(n_train):\n",
        "                    test_tsne, train_tsne = _tsne.fit_transform(test_set[i,k]), _tsne.fit_transform(train_set[c])\n",
        "                    costs[i,k,c]  = func[0](test_tsne, train_tsne)\n",
        "                    costs2[i,k,c] = func[1](test_tsne, train_tsne)\n",
        "                    costs3[i,k,c] = func[2](test_tsne, train_tsne)\n",
        "                    \n",
        "            stop = timeit.default_timer()\n",
        "            if(verbose):\n",
        "                print(\"Test class: {0}/{2} completed. Time: {1} sec. Estimated remaining time: {3} sec\".format(i+1, stop - start, n_test_class, (stop-start)*(n_test_class-i-1)))\n",
        "\n",
        "        for i in range(n_test_class):\n",
        "            for k in range(n_test_instances):\n",
        "                costs[i,k] = costs[i,k]/np.max(costs[i,k])\n",
        "                costs2[i,k] = costs2[i,k]/np.max(costs2[i,k])\n",
        "                costs3[i,k] = costs3[i,k]/np.max(costs3[i,k])\n",
        "    \n",
        "    \n",
        "    costs_res = weights[0]*costs + weights[1]*costs2 + weights[2]*costs3\n",
        "            \n",
        "    #print( costs[0])\n",
        "    #print(np.argmin(costs[0],axis=1))\n",
        "    \n",
        "    \n",
        "    if ftype == 'cost':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argpartition(costs_res[i],2,axis=1))\n",
        "        \n",
        "    elif ftype == 'score':\n",
        "        predicted_class = []\n",
        "        for i in range(n_test_class):\n",
        "            predicted_class.append(np.argmax(costs_res[i],axis=1))\n",
        "    else:\n",
        "        assert False\n",
        "    \n",
        "    correct = 0.0\n",
        "    #print(predicted_class)\n",
        "    class_scores = [0.0 for i in range(n_test_class)]\n",
        "    \n",
        "    correct2 = 0.0\n",
        "    class_scores2 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    correct3 = 0.0\n",
        "    class_scores3 = [0.0 for i in range(n_test_class)]\n",
        "\n",
        "    for i in range(n_test_class):\n",
        "        for j in range(n_test_instances):\n",
        "            if predicted_class[i][j][0] == i:\n",
        "                correct += 1\n",
        "                class_scores[i] += 1\n",
        "                plt.subplot(1,2,1)\n",
        "                plt.imshow(test_set[i,j])\n",
        "                plt.subplot(1,2,2)\n",
        "                plt.imshow(train_set[i])\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i:\n",
        "\n",
        "                correct2 += 1\n",
        "                class_scores2[i] += 1\n",
        "                \n",
        "            if predicted_class[i][j][0] == i or predicted_class[i][j][1] == i or predicted_class[i][j][2]==i:\n",
        "                correct3 += 1\n",
        "                class_scores3[i] += 1\n",
        "    plt.show()\n",
        "    if(verbose):\n",
        "        for i in range(n_test_class):\n",
        "            print(\" Class {0} : Top1 correct: {1}/{2}, Top2 correct: {3}/{2}, Top3 correct: {4}/{2}\".format(i,class_scores[i], n_test_instances,class_scores2[i],class_scores3[i]))\n",
        "\n",
        "        print(\"Total: Top1 -: {0}/{1} = {4}, Top2 -: {2}/{1} = {5}, Top3 -: {3}/{1} = {6}\".format(correct,n_test_class * n_test_instances,correct2,correct3,100 * correct / (n_test_class * n_test_instances), \\\n",
        "                                                                                                 100 * correct2 / (n_test_class * n_test_instances),100 * correct3 / (n_test_class * n_test_instances)))\n",
        "    pcorrect = 100 * correct / (n_test_class * n_test_instances)\n",
        "    perror = 100 - pcorrect\n",
        "    \n",
        "    return pcorrect,costs,costs2\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlFQKZVHWBbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b0ec82f3-99aa-469c-e37e-f86cdbb7fe00"
      },
      "cell_type": "code",
      "source": [
        "asd = new_latin[0:2]\n",
        "x ,y ,z = classification_run_tsne(latin_samples, asd,func=[jensenshannon_distance_std, braycurtis_distance_std, correlation_distance_std], weights = [-0.5317, 0.6791, -0.2474])"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test class: 1/2 completed. Time: 394.7524163370035 sec. Estimated remaining time: 394.7524163370035 sec\n",
            "Test class: 2/2 completed. Time: 396.44179641499795 sec. Estimated remaining time: 0.0 sec\n",
            " Class 0 : Top1 correct: 19.0/19, Top2 correct: 19.0/19, Top3 correct: 19.0/19\n",
            " Class 1 : Top1 correct: 0.0/19, Top2 correct: 19.0/19, Top3 correct: 19.0/19\n",
            "Total: Top1 -: 19.0/38 = 50.0, Top2 -: 38.0/38 = 100.0, Top3 -: 38.0/38 = 100.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/bedirhan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}